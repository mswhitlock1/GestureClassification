{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import numpy as np\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OS = 0 # 1 = MAC; 0 = PC\n",
    "\n",
    "COLORS_ALL = [\"green\",\"blue\",\"green\",\"gold\",\"orange\",\"orangered\",\"yellow\",\"gold\",\"orange\",\"orangered\",\n",
    "              \"yellow\",\"gold\",\"orange\",\"orangered\",\"yellow\",\"gold\",\"orange\",\"orangered\",\"yellow\",\"gold\",\n",
    "              \"orange\",\"orangered\"]\n",
    "'''\n",
    "Data class to traverse files to build up a training set\n",
    "\n",
    "directory: defines where the dataset lives on your local machine\n",
    "-- Example : \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "-- NOTE    : Set OS variable to define file system\n",
    "features: string to define which features of the hand to use.\n",
    "-- OPTIONS : 'all', 'fingertips', 'fingers_palm', 'wrist_palm'\n",
    "frames: string to define which frames of the dataset to use\n",
    "-- OPTIONS : 'all', 'first_last', 'first_middle_last', 'middle_only'\n",
    "-- OPTIONS : trim = If true, trim to start/stop frames; false = entire motion\n",
    "NUM_ESSAIS, NUM_SUBJECTS, NUM_GESTURES: Do not change if using the DHG2016 database\n",
    "'''\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, directory, features='all', frames='all', trim = True,\n",
    "                 NUM_ESSAIS = 5, NUM_SUBJECTS = 20, NUM_GESTURES = 14):\n",
    "        self.directory = directory\n",
    "        self.NUM_ESSAIS = NUM_ESSAIS\n",
    "        self.NUM_SUBJECTS = NUM_SUBJECTS\n",
    "        self.NUM_GESTURES = NUM_GESTURES\n",
    "        self.features = features\n",
    "        self.frames = frames\n",
    "        self.trim = trim\n",
    "        self.trim_data = []     # List of start/stop frames per gesture trial\n",
    "        self.trim_min = 1000\n",
    "        self.trim_max = 0\n",
    "        self.concat_X_train = []\n",
    "        self.concat_y_train = []\n",
    "        \n",
    "        # Build the y_train array, assuming X_train is ordered by gesture\n",
    "        self.y_train = np.zeros(NUM_ESSAIS * NUM_SUBJECTS * NUM_GESTURES)\n",
    "        for i in range(len(self.y_train)):\n",
    "            self.y_train[i] = int(i / (NUM_SUBJECTS * NUM_ESSAIS) + 1)\n",
    "        \n",
    "        # Traverse through the directory to build training data\n",
    "        \n",
    "        if self.trim == True :\n",
    "            self.set_trim()\n",
    "            \n",
    "        self.X_train = self.traverse_data()\n",
    "        \n",
    "    # Read in the trim data file. The format is:\n",
    "    #   gesture #\n",
    "    #   finger #\n",
    "    #   subject #\n",
    "    #   essai # (trial #)\n",
    "    #   frame of the the effective beginning of the gesture\n",
    "    #   frame of the the effective end of the gesture\n",
    "    def set_trim(self):\n",
    "        if OS == 1:\n",
    "            trim_filename = self.directory + \"/informations_troncage_sequences.txt\"\n",
    "        else:\n",
    "            trim_filename = self.directory + \"\\\\informations_troncage_sequences.txt\"\n",
    "        \n",
    "        trim_file = open(trim_filename, 'r')\n",
    "        \n",
    "        # The trim database has some out-of-order elements so after reading it in, re-sort to fix it.\n",
    "        for line in trim_file:\n",
    "            numbers = [int(x) for x in line.split(' ')]\n",
    "            self.trim_data.append(numbers)\n",
    "        self.trim_data = sorted(sorted(sorted(sorted(self.trim_data, key = lambda x : x[3]), key = lambda x : x[1]),key = lambda x : x[2]), key = lambda x : x[0])\n",
    "    \n",
    "        # Find the max and min lengths in case padding is needed\n",
    "        for line in self.trim_data:\n",
    "            self.trim_min = min(self.trim_min,line[5]-line[4]+1)\n",
    "            self.trim_max = max(self.trim_min,line[5]-line[4]+1)\n",
    "            \n",
    "    # Traverse to parse each \"skeleton_world.txt\" file in the directory\n",
    "    def traverse_data(self):\n",
    "        \n",
    "        trials = []\n",
    "        for gesture_num in range(1, self.NUM_GESTURES + 1):\n",
    "            for subject_num in range(1, self.NUM_SUBJECTS + 1):\n",
    "                for essai_num in range(1, self.NUM_ESSAIS + 1):\n",
    "                    \n",
    "                    if self.trim == True:\n",
    "                        index = (gesture_num - 1)* 2 * self.NUM_SUBJECTS * self.NUM_ESSAIS \\\n",
    "                            + (subject_num - 1) * 2 * self.NUM_ESSAIS \\\n",
    "                            + essai_num - 1\n",
    "\n",
    "                        # a quick self-check on the dataset to make sure we're aligned\n",
    "                        if (gesture_num != self.trim_data[index][0]) or (subject_num != self.trim_data[index][2]) \\\n",
    "                            or (essai_num != self.trim_data[index][3]) :\n",
    "                            print(\"Error in truncage file sync: Gesture: \",gesture_num,\" Subject: \",subject_num,\" Trial: \",essai_num,\n",
    "                             \"index: \",index,\"trim: \",self.trim_data[index])\n",
    "                                               \n",
    "                    else:\n",
    "                        index = 0\n",
    "                        \n",
    "                    if OS == 1:\n",
    "                        trials.append(self.parse_frames(self.directory + \"/gesture_\" + \n",
    "                                                        str(gesture_num) + \"/finger_1/subject_\" + str(subject_num) + \n",
    "                                                        \"/essai_\" + str(essai_num) + \"/skeleton_world.txt\",index))\n",
    "                    else:\n",
    "                        trials.append(self.parse_frames(self.directory + \"\\\\gesture_\" + \n",
    "                                                        str(gesture_num) + \"\\\\finger_1\\\\subject_\" + str(subject_num) + \n",
    "                                                        \"\\\\essai_\" + str(essai_num) + \"\\\\skeleton_world.txt\",index))\n",
    "        return trials\n",
    "    \n",
    "    # Entry point to parse a particular file--filtering based on self.frames and self.features\n",
    "    def parse_frames(self, filename,index):\n",
    "        file = open(filename, 'r')\n",
    "        lines = []\n",
    "        for line in file:\n",
    "            lines.append(line)\n",
    "            \n",
    "        # If trimming is enabled, trim to the start/stop limits defined in the truncation file\n",
    "        if self.trim == True:\n",
    "            lines = lines[self.trim_data[index][4]:self.trim_data[index][5]+1]\n",
    "        else:\n",
    "            lines = lines[0:len(lines)]                \n",
    "        \n",
    "        # Set the 'frames' dimension based on how the data should be sampled\n",
    "        if self.frames == 'all':\n",
    "            num_frames = len(lines)\n",
    "        elif self.frames == 'first_last':\n",
    "            num_frames = 2\n",
    "        elif self.frames == 'first_middle_last':\n",
    "            num_frames = 3\n",
    "        elif self.frames == 'middle_only':\n",
    "            num_frames = 1\n",
    "        \n",
    "        # Set the 'features' dimension based on how the data should be sampled\n",
    "        if self.features == 'all':\n",
    "            num_features = 22\n",
    "        elif self.features == 'fingertips':\n",
    "            num_features = 5\n",
    "        elif self.features == 'wrist_palm':\n",
    "            num_features = 3\n",
    "        elif self.features == 'fingers_palm':\n",
    "            num_features = 6\n",
    "            \n",
    "        frames = []\n",
    "        \n",
    "        # Add frames in a particular way, depending on the filtering strategy\n",
    "        if self.frames == 'all':\n",
    "            for i in range(len(lines)):\n",
    "                line = lines[i]\n",
    "                frames.append(self.parse_frame(line))\n",
    "                \n",
    "        elif self.frames == 'first_last':\n",
    "            frames.append(self.parse_frame(lines[0]))\n",
    "            frames.append(self.parse_frame(lines[len(lines) - 1]))\n",
    "            \n",
    "        elif self.frames == 'first_middle_last':\n",
    "            frames.append(self.parse_frame(lines[0]))\n",
    "            frames.append(self.parse_frame(lines[int(len(lines) / 2)]))\n",
    "            frames.append(self.parse_frame(lines[len(lines) - 1]))\n",
    "            \n",
    "        elif self.frames == 'middle_only':\n",
    "            frames.append(self.parse_frame(lines[int(len(lines) / 2)]))\n",
    "            \n",
    "        return frames\n",
    "\n",
    "    # Parse an individual frame (line in a file)\n",
    "    def parse_frame(self, line):\n",
    "        numbers = line.split(' ')\n",
    "        full_frame = np.zeros((22,3))\n",
    "        \n",
    "        for j in range(len(numbers)):\n",
    "            full_frame[int(j / 3)][j % 3] = numbers[j]\n",
    "        \n",
    "        # Add features on the hand in a particular way, depending on the filtering strategy\n",
    "        \n",
    "        frame = []\n",
    "        if self.features == 'all':\n",
    "            for i in range (0,22):\n",
    "                frame.append([full_frame[i],COLORS_ALL[i]])\n",
    "            return frame\n",
    "        \n",
    "        elif self.features == 'fingertips':\n",
    "            frame.append([full_frame[5],COLORS_ALL[5]])\n",
    "            frame.append([full_frame[9],COLORS_ALL[9]])\n",
    "            frame.append([full_frame[13],COLORS_ALL[13]])\n",
    "            frame.append([full_frame[17],COLORS_ALL[17]])\n",
    "            frame.append([full_frame[21],COLORS_ALL[21]])\n",
    "            return frame\n",
    "        \n",
    "        elif self.features == 'wrist_palm':\n",
    "            frame.append([full_frame[0],COLORS_ALL[0]])\n",
    "            frame.append([full_frame[1],COLORS_ALL[1]])\n",
    "            frame.append([full_frame[2],COLORS_ALL[2]])\n",
    "            return frame\n",
    "\n",
    "        elif self.features == 'fingers_palm':\n",
    "            frame.append([full_frame[1],COLORS_ALL[1]])\n",
    "            frame.append([full_frame[5],COLORS_ALL[5]])\n",
    "            frame.append([full_frame[9],COLORS_ALL[9]])\n",
    "            frame.append([full_frame[13],COLORS_ALL[13]])\n",
    "            frame.append([full_frame[17],COLORS_ALL[17]])\n",
    "            frame.append([full_frame[21],COLORS_ALL[21]])\n",
    "            return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random as rnd\n",
    "\n",
    "# When instantiated, this class will take the data of class Data and perform the modifications defined in \n",
    "# the pass parameter mods. The mods are performed in a defined sequence. A step in the sequence may be \n",
    "# skipped by not passing in a request for that mod but the order of the mods cannot be changed (e.g translate\n",
    "# will always occur before scale.\n",
    "\n",
    "# See the individual mods for a description of their algorithm.\n",
    "# Inputs:\n",
    "#   data: a Data class structure\n",
    "#   mods: a string containing the mods to perform in the order that the mods should be performed\n",
    "#\n",
    "class Data_Mods:\n",
    "    def __init__(self,data,mods):\n",
    "        \n",
    "        self.raw_X_train = data.X_train\n",
    "        self.raw_y_train = data.y_train\n",
    "        \n",
    "        self.mod_X_train = cp.deepcopy(data.X_train)   # A working array to hold the data as it's modified\n",
    "        self.mod_y_train = cp.deepcopy(data.y_train)\n",
    "\n",
    "        self.X_train = cp.deepcopy(data.X_train)\n",
    "        self.y_train = cp.deepcopy(data.y_train)\n",
    "        \n",
    "        self.X_test = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        # Take apart the mods string here one string at a time and call the associated function\n",
    "        switcher = {\n",
    "                    \"center\":    self.center,\n",
    "                    \"translate\": self.translate,\n",
    "                    \"scale\":     self.scale,\n",
    "                    \"angles\":    self.angles,\n",
    "                    \"delta\":     self.delta\n",
    "                    }\n",
    "\n",
    "        debug = False\n",
    "\n",
    "        if debug == True:\n",
    "            printFrame(self.raw_X_train[0][0])\n",
    "            display(self.raw_X_train[0]) \n",
    "\n",
    "        # A python switch statement...\n",
    "        for key in mods.split(\" \"):\n",
    "            print(\"Performing \",key,\" modification\")\n",
    "            func = switcher.get(key, \"nothing\")\n",
    "            if func == \"nothing\":\n",
    "                print(\"key: \",key,\" is invalid\")\n",
    "            else:\n",
    "                func()\n",
    "                if debug == True:\n",
    "                    printFrame(self.mod_X_train[0][0])\n",
    "                    display(self.mod_X_train[0]) \n",
    "\n",
    "    def minMax(self,val,lmin,lmax,lsum):\n",
    "        \n",
    "        if val < lmin:\n",
    "            lmin = val\n",
    "        elif val > lmax:\n",
    "            lmax = val\n",
    "\n",
    "        lsum += val\n",
    "\n",
    "        return(lmin,lmax,lsum)\n",
    "            \n",
    "    # This function collects various stats about the data frame passed in\n",
    "    def stats(self,frame):\n",
    "        x_min  = 10000\n",
    "        x_max  = -10000\n",
    "        x_mean = 0\n",
    "        \n",
    "        y_min = 10000\n",
    "        y_max = -10000\n",
    "        y_mean = 0\n",
    "        \n",
    "        z_min = 10000\n",
    "        z_max = -10000\n",
    "        z_mean = 0\n",
    "            \n",
    "        joint_cnt = 0\n",
    "        for joint in frame:\n",
    "            [x_min,x_max,x_mean] = self.minMax(joint[0][0],x_min,x_max,x_mean)\n",
    "            [y_min,y_max,y_mean] = self.minMax(joint[0][1],y_min,y_max,y_mean)\n",
    "            [z_min,z_max,z_mean] = self.minMax(joint[0][2],z_min,z_max,z_mean)\n",
    "            \n",
    "            joint_cnt += 1\n",
    "        \n",
    "        x_mean = x_mean/joint_cnt\n",
    "        y_mean = y_mean/joint_cnt\n",
    "        z_mean = z_mean/joint_cnt\n",
    "        \n",
    "        return (x_min,x_mean,x_max,y_min,y_mean,y_max,z_min,z_mean,z_max)\n",
    "        \n",
    "    # This function translates all the gestures such that the wrist (point 0)\n",
    "    # resides at 0.5, 0.5, 0.5 to remove variation between trials and subjects\n",
    "    # \n",
    "    # The input is the sequence of frames for a gesture where the array dimensions are:\n",
    "    #     [trial #][frame #][hand joint #][position array = 0, color = 1][x = 0, y = 1, z = 2]\n",
    "    def center(self):\n",
    "        \n",
    "        # find the global mins for each axis\n",
    "        gx_min = 1000\n",
    "        gy_min = 1000\n",
    "        gz_min = 1000\n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                [x_min,x_mean,x_max,y_min,y_mean,y_max,z_min,z_mean,z_max] = self.stats(frame)\n",
    "                if x_min < gx_min:\n",
    "                    gx_min = x_min\n",
    "\n",
    "                if y_min < gy_min:\n",
    "                    gy_min = y_min\n",
    "                    \n",
    "                if z_min < gz_min:\n",
    "                    gz_min = z_min\n",
    "         \n",
    "        # Center all the frames up by the global min or 1.0 which ever is greater so there \n",
    "        # are no negative coordinates\n",
    "        \n",
    "        offset_x = 1.0\n",
    "        offset_y = 1.0\n",
    "        offset_z = 1.0\n",
    "        \n",
    "        if gx_min < 0:\n",
    "            offset_x += abs(gx_min)\n",
    "        if gy_min < 0:\n",
    "            offset_y += abs(gy_min)\n",
    "        if gz_min < 0:\n",
    "            offset_z += + abs(gz_min)\n",
    "            \n",
    "#        print(gx_min,gy_min,gz_min)\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            \n",
    "            # Calculate how far to move this trial to be centered on the common point\n",
    "            cx = offset_x - trial[0][0][0][0]\n",
    "            cy = offset_y - trial[0][0][0][1]\n",
    "            cz = offset_z - trial[0][0][0][2]\n",
    "            \n",
    "            # Move all the data points in each frame for this trial by that common offset\n",
    "            for frame in trial:\n",
    "                for joint in frame:\n",
    "                    joint[0][0] += cx\n",
    "                    joint[0][1] += cy\n",
    "                    joint[0][2] += cz\n",
    "             \n",
    "    # Perform a Procustes translation\n",
    "    # \n",
    "    # Modifies the mod data frames where all x, y, z coordinates are divided by the x mean, y mean, z mean respectively\n",
    "    def translate(self):\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                [x_min,x_mean,x_max,y_min,y_mean,y_max,z_min,z_mean,z_max] = self.stats(frame)\n",
    "                for joint in frame:\n",
    "                    joint[0][0] = joint[0][0]/x_mean\n",
    "                    joint[0][1] = joint[0][1]/y_mean\n",
    "                    joint[0][2] = joint[0][2]/z_mean                \n",
    "\n",
    "    def scale(self):\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                lsum = 0\n",
    "                for joint in frame:\n",
    "                    lsum += joint[0][0]**2 + joint[0][1]**2 + joint[0][2]**2\n",
    "                lscale = math.sqrt(lsum/len(frame))\n",
    "             \n",
    "                for joint in frame:\n",
    "                    joint[0][0] = joint[0][0]/lscale\n",
    "                    joint[0][1] = joint[0][1]/lscale\n",
    "                    joint[0][2] = joint[0][2]/lscale                \n",
    "  \n",
    "    # This function coverts from X, Y, Z coordinates to X-Y Angle, X-Z Angle, Vector Length.\n",
    "    # The angles returned are in radians.\n",
    "    #\n",
    "    # Output:\n",
    "    #    Joint[0][0] = X-Y angle\n",
    "    #    Joint[0][1] = X-Z angle\n",
    "    #    Joint[0][2] = Vector length\n",
    "    \n",
    "    def angles(self):\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                for joint in frame:\n",
    "                    x = joint[0][0]\n",
    "                    y = joint[0][1]\n",
    "                    z = joint[0][2]\n",
    "                    joint[0][0] = math.atan(y/x)\n",
    "                    joint[0][1] = math.atan(z/x)\n",
    "                    joint[0][2] = math.sqrt(x**2 + y**2 + z**2)\n",
    "      \n",
    "    # This function converts a trial from a series of frames containing absolute X, Y, Z \n",
    "    # locations to a delta between each frame. There are Frame - 1 deltas here so the last element\n",
    "    # of the array holding the modified data gets truncated by one.\n",
    "    #\n",
    "    # Output:\n",
    "    #    Joint[0][0] = X(t-1) - X(t)\n",
    "    #    Joint[0][1] = Y(t-1) - Y(t)\n",
    "    #    Joint[0][2] = Z(t-1) - Z(t)\n",
    "\n",
    "    def delta(self):\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in range(len(trial)-1):\n",
    "                for joint in range(len(trial[frame])):\n",
    "                    trial[frame][joint][0][0] = trial[frame][joint][0][0] - trial[frame+1][joint][0][0]\n",
    "                    trial[frame][joint][0][1] = trial[frame][joint][0][1] - trial[frame+1][joint][0][1]\n",
    "                    trial[frame][joint][0][2] = trial[frame][joint][0][2] - trial[frame+1][joint][0][2]\n",
    "\n",
    "            trial.pop(len(trial)-1)\n",
    "\n",
    "    # This function creates vectors out of the data. \n",
    "    #   data_set - \"raw\" = use the original, unmodified data\n",
    "    #              \"modified\" = use the modified data \n",
    "    #\n",
    "    #   concat - \"by_frame\" = Each trial, each frame will be individually concatenated into a vector (frame \n",
    "    #                         vectors) and the trial will have the dimensionality of the number of frames in \n",
    "    #                         that trial. The trial is now a frames dimensional list of frame vectors \n",
    "    #            \"all\" = For each trial, all frames for a that trial are concatenated together in order of time stamp\n",
    "    def concatenate(self,data_set=\"raw\",concat=\"by_frame\"):\n",
    "        if data_set == 'modified':\n",
    "            data = self.mod_X_train\n",
    "        else:\n",
    "            data = self.raw_X_train\n",
    "            \n",
    "        gest_cnt = 0\n",
    "        concat_X_train = []\n",
    "        concat_y_train = []\n",
    "\n",
    "        for trial in data:\n",
    "            if concat == \"by_frame\":\n",
    "                tmp_frame = []\n",
    "                for frame in trial:\n",
    "                    tmp_axis = []\n",
    "                    for joint in frame:\n",
    "                        for axis in joint[0]:\n",
    "                            tmp_axis.append(axis)\n",
    "                    tmp_frame.append(tmp_axis)\n",
    "                concat_X_train.append(np.array(tmp_frame))\n",
    "                concat_y_train.append(self.raw_y_train[gest_cnt])\n",
    "                gest_cnt += 1\n",
    "            else: #\"all\"\n",
    "                tmp_work = []\n",
    "                for frame in trial:\n",
    "                    for joint in frame:\n",
    "                        for axis in joint[0]:\n",
    "                            tmp_work.append(axis)\n",
    "                concat_X_train.append(np.array(tmp_work))\n",
    "                concat_y_train.append(self.raw_y_train[gest_cnt])\n",
    "                gest_cnt += 1\n",
    "\n",
    "        return (np.array(concat_X_train),np.array(concat_y_train))\n",
    "\n",
    "    # This function does a basic randomization. It takes the dataset passed in\n",
    "    # and sets X_train, y_train to a randomized version of it\n",
    "    def shuffle(self,data_x,data_y):\n",
    "        random_indices = rnd.sample(range(len(data_x)), len(data_x))\n",
    "        new_i = 0\n",
    "        for i in random_indices:\n",
    "            self.X_train[new_i] = data_x[i]\n",
    "            self.y_train[new_i] = data_y[i]\n",
    "            new_i += 1\n",
    "            \n",
    "        self.X_train = np.array(self.X_train)\n",
    "        self.y_train = np.array(self.y_train)\n",
    "        \n",
    "    # This function sets aside pct of the data passed in for the training set and the \n",
    "    # remaining 1-pct as the test set\n",
    "    #\n",
    "    # pct     - percent split between training and test\n",
    "    # gesture - -1 if all gestures included, >= 0 defines gesture that will have y = 1\n",
    "    #           all other gestures will be -1\n",
    "    #\n",
    "    # Note: This function needs to be called after shuffle\n",
    "    def split_data(self,ratio):\n",
    "        X_data = cp.deepcopy(self.X_train)\n",
    "        y_data = cp.deepcopy(self.y_train)\n",
    "\n",
    "        train_length = int(ratio * self.X_train.shape[0])\n",
    "        self.X_test  = np.array(X_data[train_length:])\n",
    "        self.X_train = np.array(X_data[:train_length])\n",
    "        \n",
    "        self.y_test  = np.array(y_data[train_length:])\n",
    "        self.y_train = np.array(y_data[:train_length])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d78542ceaa43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmyPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Include all data points, all frames\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#data = Data(myPath, features = 'fingertips', frames='first_middle_last') # fingertips only, using 3 frames at beginning middle, end of the gesture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#data = Data(myPath, features = 'wrist_palm', frames='middle_only') # wrist and palm points using only the middle frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-2ce842834651>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, features, frames, trim, NUM_ESSAIS, NUM_SUBJECTS, NUM_GESTURES)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# Build the y_train array, assuming X_train is ordered by gesture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_ESSAIS\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mNUM_SUBJECTS\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mNUM_GESTURES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNUM_SUBJECTS\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mNUM_ESSAIS\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#myPath = \"/home/jovyan/data\"\n",
    "myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "\n",
    "data = Data(myPath, features = 'all', frames='all',trim=True) # Include all data points, all frames\n",
    "#data = Data(myPath, features = 'fingertips', frames='first_middle_last') # fingertips only, using 3 frames at beginning middle, end of the gesture\n",
    "#data = Data(myPath, features = 'wrist_palm', frames='middle_only') # wrist and palm points using only the middle frame\n",
    "\n",
    "#display(data.X_train[0]) # plot (in 2D the first gesture in the training set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up an SVM Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes only: display each frame of the trial passed in\n",
    "def display(trial):\n",
    "            \n",
    "    f_cnt = 0\n",
    "    for frame in trial:\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        clr = []\n",
    "        \n",
    "        for feature in frame:\n",
    "            x_vals.append(feature[0][0])\n",
    "            y_vals.append(feature[0][1])\n",
    "            clr.append(feature[1])\n",
    "            \n",
    "        plt.scatter(x_vals, y_vals,c=clr)\n",
    "        plt.title(\"Frame \" + str(f_cnt))\n",
    "        plt.show()\n",
    "        f_cnt += 1\n",
    "\n",
    "# Another helper function to print out a frame\n",
    "def printFrame(frame):\n",
    "\n",
    "    print(\"   X      Y     Z    Color\")\n",
    "    for feature in frame:\n",
    "        print(\"{0:6.3f} {1:6.3f} {2:6.3f} {3}\".format(feature[0][0],feature[0][1],feature[0][2],feature[1]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "MAX_ITER = 5\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return (1 + np.dot(x1, x2))\n",
    "    \n",
    "def polynomial_kernel(x1, x2, p = 3):\n",
    "    return (1 + np.dot(x1, x2)) ** p\n",
    "    \n",
    "def gaussian_kernel(x1, x2, sigma = 0.5):\n",
    "    return np.exp(-LA.norm(x1-x2)**2 / (2 * (sigma ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPerceptron:\n",
    "    def __init__(self, kernel = linear_kernel, Niter = 1):\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.Niter = Niter\n",
    "        self.support_vector_x = None\n",
    "        self.support_vector_y = None\n",
    "        self.alpha = []\n",
    "        self.bias = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        self.alpha = np.zeros(n_samples, dtype=np.float64)\n",
    "        self.bias = np.zeros(n_samples, dtype=np.float64)\n",
    "\n",
    "        for iter in range(self.Niter):\n",
    "            for i in range(n_samples):\n",
    "                sum = 0\n",
    "                for j in range(n_samples): \n",
    "                    sum += self.alpha[j]*y[j]*(self.kernel(X[j],X[i]))\n",
    "                if sum * y[i] <= 0:\n",
    "                    self.alpha[i] += 1\n",
    "                   \n",
    "      # Support vectors\n",
    "        sv = self.alpha > 1e-5 # ignore really small alphas - probably rounding issues\n",
    "        self.alpha = self.alpha[sv]\n",
    "        self.bias = self.bias[sv]\n",
    "        self.support_vector_x = X[sv]\n",
    "        self.support_vector_y = y[sv]\n",
    "        print(np.count_nonzero(sv),\" support vectors.\")    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        y_predict = np.zeros(len(X))\n",
    "        for i in range(len(X)):\n",
    "            sum = 0\n",
    "            for j in range(len(self.alpha)):\n",
    "                sum += self.alpha[j] * self.support_vector_y[j] * self.kernel(X[i], self.support_vector_x[j]+self.bias[j])\n",
    "            y_predict[i] = sum\n",
    "        return np.sign(y_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(X_train, y_train, ratio):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n (int): total size of the training data\n",
    "        X_train (ndarray): [n_samples x n_features] ndarray of training data   \n",
    "        y_train (ndarray): [n_samples] ndarray of data \n",
    "    \"\"\"\n",
    "    selected_indices = np.random.randint(y_train.shape[0], size=int(ratio * y_train.shape[0]))\n",
    "    return [X_train[i] for i in selected_indices], [y_train[i] for i in selected_indices]\n",
    "def voting(y_hats):\n",
    "    counts = dict()\n",
    "    for i in y_hats:\n",
    "        counts[int(i)] = counts.get(int(i), 0) + 1\n",
    "    class_num, count = max((class_num, count) for class_num, count in counts.items())\n",
    "    return class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing  center  modification\n",
      "Raw, single vector per trial\n",
      "(1400, 54)\n",
      "[ 0.362 -0.338  0.373  0.284 -0.31   0.386  0.354 -0.236  0.407  0.401\n",
      " -0.232  0.409  0.423 -0.234  0.394  0.446 -0.262  0.371  0.37  -0.295\n",
      "  0.399  0.256 -0.272  0.368  0.341 -0.184  0.407  0.315 -0.217  0.331\n",
      "  0.339 -0.231  0.337  0.381 -0.231  0.352  0.355 -0.259  0.376  0.296\n",
      " -0.218  0.336  0.283 -0.215  0.313  0.351 -0.253  0.361  0.37  -0.26\n",
      "  0.367  0.39  -0.264  0.374]\n",
      "1.0\n",
      "\n",
      "\n",
      "Modified, single vector per trial\n",
      "(1400, 54)\n",
      "[1.042 1.796 1.    0.963 1.824 1.013 1.033 1.898 1.034 1.081 1.902 1.036\n",
      " 1.102 1.9   1.02  1.125 1.872 0.997 1.05  1.839 1.025 0.935 1.862 0.995\n",
      " 1.02  1.95  1.033 0.995 1.917 0.958 1.019 1.903 0.964 1.06  1.903 0.978\n",
      " 1.035 1.875 1.003 0.976 1.916 0.962 0.963 1.919 0.939 1.031 1.881 0.987\n",
      " 1.05  1.874 0.993 1.07  1.87  1.001]\n",
      "1.0\n",
      "\n",
      "\n",
      "Modified, vector for each frame of trial\n",
      "(1400, 3, 18)\n",
      "[[1.042 1.796 1.    0.963 1.824 1.013 1.033 1.898 1.034 1.081 1.902 1.036\n",
      "  1.102 1.9   1.02  1.125 1.872 0.997]\n",
      " [1.05  1.839 1.025 0.935 1.862 0.995 1.02  1.95  1.033 0.995 1.917 0.958\n",
      "  1.019 1.903 0.964 1.06  1.903 0.978]\n",
      " [1.035 1.875 1.003 0.976 1.916 0.962 0.963 1.919 0.939 1.031 1.881 0.987\n",
      "  1.05  1.874 0.993 1.07  1.87  1.001]]\n",
      "1.0\n",
      "\n",
      "\n",
      "Looking at just the middle frames for the first three trials\n",
      "(1400, 18)\n",
      "[[1.05  1.839 1.025 0.935 1.862 0.995 1.02  1.95  1.033 0.995 1.917 0.958\n",
      "  1.019 1.903 0.964 1.06  1.903 0.978]\n",
      " [1.048 1.852 0.986 0.966 1.874 0.928 0.977 1.968 0.94  1.043 1.857 0.973\n",
      "  1.03  1.876 0.939 1.073 1.873 0.957]\n",
      " [1.024 1.818 0.996 0.929 1.809 0.973 0.988 1.926 0.986 1.002 1.829 0.976\n",
      "  1.02  1.826 0.978 1.026 1.82  0.974]]\n",
      "\n",
      "\n",
      "pre-split X_train size: (1400, 54)\n",
      "pre-split y_train size: (1400,)\n",
      "pre-split X_train size: (1120, 54)\n",
      "pre-split y_train size: (1120,)\n",
      "pre-split X_test size: (280, 54)\n",
      "pre-split y_test size: (280,)\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovo', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "(280, 14)\n",
      "[[-0.413  8.07   1.704 ...  0.704 11.184  2.81 ]\n",
      " [-0.407  8.075  1.703 ...  0.706 11.184  2.808]\n",
      " [-0.43   8.005  0.67  ...  1.753 11.191  2.829]\n",
      " ...\n",
      " [-0.438  5.968  0.671 ...  2.803 11.282  2.824]\n",
      " [-0.394 10.187  1.728 ...  0.658 10.089  2.803]\n",
      " [-0.411  8.066  1.692 ...  0.701 11.148  2.817]]\n",
      "[-0.413  8.07   1.704 10.249  9.116  6.016  7.065  3.893  4.93  12.334\n",
      " 13.339  0.704 11.184  2.81 ]\n",
      "[ 9. 14.  3. 14.  1.  5. 14. 14.  7. 14.  5.  2. 13. 12.  4.  4.  1. 12.\n",
      "  3. 12.  8. 12. 13.  1.  9.  6.  1. 11.  1.  2. 13.  9.  1.  9.  7.  9.\n",
      "  5. 14. 12.  9. 12. 10.  9. 14.  1.  9.  5. 12. 10.  3.  2.  4. 10.  1.\n",
      " 14.  5.  4.  6.  9.  4.  9. 10. 14.  5.  5.  7. 14. 13.  6.  2.  1.  5.\n",
      " 13.  9.  5.  6.  9.  6.  8.  8. 14.  7.  1.  6.  8.  6. 10. 11.  8.  6.\n",
      " 12. 13. 12.  1.  7.  8. 11.  3.  9.  8.  5.  6.  2.  1. 14. 13. 12.  7.\n",
      "  2.  5.  1. 12.  7. 13. 13.  3. 10.  1. 14. 13.  5.  3. 11. 12.  5. 14.\n",
      "  1.  1. 11.  6.  2.  4.  7.  3.  2.  5.  4.  3.  7.  4.  1.  6. 10.  2.\n",
      " 14.  7.  8.  4.  1.  6.  7.  6.  6.  3.  8. 14. 14.  8. 11.  3. 10.  7.\n",
      "  1.  3.  8. 10.  4. 11. 14.  4.  8.  1.  1.  8. 12.  9. 11. 12.  1.  9.\n",
      "  7.  4.  2.  3.  8.  7.  5.  9. 12.  6.  5.  2.  6.  8.  8.  1.  2. 14.\n",
      "  8. 13.  7. 12.  9.  8.  9.  3.  9. 12.  2.  8.  1.  9. 11.  4.  2.  1.\n",
      "  3.  5.  2.  1. 10. 14. 12. 13.  3. 13. 12. 10.  5.  3.  3. 10.  7.  1.\n",
      "  3.  4. 13.  3.  8. 11.  1.  4. 14.  2. 12.  3.  2. 10.  5.  7. 11.  1.\n",
      " 14.  3. 13. 10.  1.  6.  3. 12.  2.  3.  3.  7.  3. 10.  7. 12.  6.  4.\n",
      " 12.  6. 12.  9. 12.  4.  8. 13.  2.  6.]\n",
      "0 10 9.0\n",
      "1 10 14.0\n",
      "2 10 3.0\n",
      "3 10 14.0\n",
      "4 10 1.0\n",
      "5 10 5.0\n",
      "6 10 14.0\n",
      "7 10 14.0\n",
      "8 10 7.0\n",
      "9 10 14.0\n",
      "10 10 5.0\n",
      "11 10 2.0\n",
      "12 10 13.0\n",
      "13 10 12.0\n",
      "14 10 4.0\n",
      "15 10 4.0\n",
      "16 10 1.0\n",
      "17 10 12.0\n",
      "18 10 3.0\n",
      "19 10 12.0\n",
      "20 10 8.0\n",
      "21 10 12.0\n",
      "22 10 13.0\n",
      "23 10 1.0\n",
      "24 10 9.0\n",
      "25 10 6.0\n",
      "26 10 1.0\n",
      "27 10 11.0\n",
      "28 10 1.0\n",
      "29 10 2.0\n",
      "30 10 13.0\n",
      "31 10 9.0\n",
      "32 10 1.0\n",
      "33 10 9.0\n",
      "34 10 7.0\n",
      "35 10 9.0\n",
      "36 10 5.0\n",
      "37 10 14.0\n",
      "38 10 12.0\n",
      "39 10 9.0\n",
      "40 10 12.0\n",
      "42 10 9.0\n",
      "43 10 14.0\n",
      "44 10 1.0\n",
      "45 10 9.0\n",
      "46 10 5.0\n",
      "47 10 12.0\n",
      "49 10 3.0\n",
      "50 10 2.0\n",
      "51 10 4.0\n",
      "53 10 1.0\n",
      "54 10 14.0\n",
      "55 10 5.0\n",
      "56 10 4.0\n",
      "57 10 6.0\n",
      "58 10 9.0\n",
      "59 10 4.0\n",
      "60 10 9.0\n",
      "62 10 14.0\n",
      "63 10 5.0\n",
      "64 10 5.0\n",
      "65 10 7.0\n",
      "66 10 14.0\n",
      "67 10 13.0\n",
      "68 10 6.0\n",
      "69 10 2.0\n",
      "70 10 1.0\n",
      "71 10 5.0\n",
      "72 10 13.0\n",
      "73 10 9.0\n",
      "74 10 5.0\n",
      "75 10 6.0\n",
      "76 10 9.0\n",
      "77 10 6.0\n",
      "78 10 8.0\n",
      "79 10 8.0\n",
      "80 10 14.0\n",
      "81 10 7.0\n",
      "82 10 1.0\n",
      "83 10 6.0\n",
      "84 10 8.0\n",
      "85 10 6.0\n",
      "87 10 11.0\n",
      "88 10 8.0\n",
      "89 10 6.0\n",
      "90 10 12.0\n",
      "91 10 13.0\n",
      "92 10 12.0\n",
      "93 10 1.0\n",
      "94 10 7.0\n",
      "95 10 8.0\n",
      "96 10 11.0\n",
      "97 10 3.0\n",
      "98 10 9.0\n",
      "99 10 8.0\n",
      "100 10 5.0\n",
      "101 10 6.0\n",
      "102 10 2.0\n",
      "103 10 1.0\n",
      "104 10 14.0\n",
      "105 10 13.0\n",
      "106 10 12.0\n",
      "107 10 7.0\n",
      "108 10 2.0\n",
      "109 10 5.0\n",
      "110 10 1.0\n",
      "111 10 12.0\n",
      "112 10 7.0\n",
      "113 10 13.0\n",
      "114 10 13.0\n",
      "115 10 3.0\n",
      "117 10 1.0\n",
      "118 10 14.0\n",
      "119 10 13.0\n",
      "120 10 5.0\n",
      "121 10 3.0\n",
      "122 10 11.0\n",
      "123 10 12.0\n",
      "124 10 5.0\n",
      "125 10 14.0\n",
      "126 10 1.0\n",
      "127 10 1.0\n",
      "128 10 11.0\n",
      "129 10 6.0\n",
      "130 10 2.0\n",
      "131 10 4.0\n",
      "132 12 7.0\n",
      "133 10 3.0\n",
      "134 10 2.0\n",
      "135 10 5.0\n",
      "136 10 4.0\n",
      "137 10 3.0\n",
      "138 10 7.0\n",
      "139 10 4.0\n",
      "140 10 1.0\n",
      "141 10 6.0\n",
      "143 10 2.0\n",
      "144 10 14.0\n",
      "145 10 7.0\n",
      "146 10 8.0\n",
      "147 10 4.0\n",
      "148 10 1.0\n",
      "149 10 6.0\n",
      "150 10 7.0\n",
      "151 10 6.0\n",
      "152 10 6.0\n",
      "153 10 3.0\n",
      "154 10 8.0\n",
      "155 10 14.0\n",
      "156 10 14.0\n",
      "157 10 8.0\n",
      "158 10 11.0\n",
      "159 10 3.0\n",
      "161 12 7.0\n",
      "162 10 1.0\n",
      "163 10 3.0\n",
      "164 10 8.0\n",
      "166 10 4.0\n",
      "167 10 11.0\n",
      "168 10 14.0\n",
      "169 10 4.0\n",
      "170 10 8.0\n",
      "171 10 1.0\n",
      "172 10 1.0\n",
      "173 10 8.0\n",
      "174 10 12.0\n",
      "175 10 9.0\n",
      "176 10 11.0\n",
      "177 10 12.0\n",
      "178 10 1.0\n",
      "179 10 9.0\n",
      "180 10 7.0\n",
      "181 10 4.0\n",
      "182 10 2.0\n",
      "183 10 3.0\n",
      "184 10 8.0\n",
      "185 10 7.0\n",
      "186 10 5.0\n",
      "187 10 9.0\n",
      "188 10 12.0\n",
      "189 10 6.0\n",
      "190 10 5.0\n",
      "191 10 2.0\n",
      "192 10 6.0\n",
      "193 10 8.0\n",
      "194 10 8.0\n",
      "195 10 1.0\n",
      "196 10 2.0\n",
      "197 10 14.0\n",
      "198 10 8.0\n",
      "199 10 13.0\n",
      "200 10 7.0\n",
      "201 10 12.0\n",
      "202 10 9.0\n",
      "203 10 8.0\n",
      "204 10 9.0\n",
      "205 10 3.0\n",
      "206 10 9.0\n",
      "207 10 12.0\n",
      "208 10 2.0\n",
      "209 10 8.0\n",
      "210 10 1.0\n",
      "211 10 9.0\n",
      "212 10 11.0\n",
      "213 10 4.0\n",
      "214 10 2.0\n",
      "215 10 1.0\n",
      "216 10 3.0\n",
      "217 10 5.0\n",
      "218 10 2.0\n",
      "219 10 1.0\n",
      "221 10 14.0\n",
      "222 10 12.0\n",
      "223 10 13.0\n",
      "224 10 3.0\n",
      "225 10 13.0\n",
      "226 10 12.0\n",
      "228 10 5.0\n",
      "229 10 3.0\n",
      "230 10 3.0\n",
      "232 10 7.0\n",
      "233 10 1.0\n",
      "234 10 3.0\n",
      "235 10 4.0\n",
      "236 10 13.0\n",
      "237 10 3.0\n",
      "238 10 8.0\n",
      "239 10 11.0\n",
      "240 10 1.0\n",
      "241 10 4.0\n",
      "242 10 14.0\n",
      "243 10 2.0\n",
      "244 10 12.0\n",
      "245 10 3.0\n",
      "246 10 2.0\n",
      "248 10 5.0\n",
      "249 10 7.0\n",
      "250 10 11.0\n",
      "251 10 1.0\n",
      "252 10 14.0\n",
      "253 10 3.0\n",
      "254 10 13.0\n",
      "256 10 1.0\n",
      "257 10 6.0\n",
      "258 10 3.0\n",
      "259 10 12.0\n",
      "260 10 2.0\n",
      "261 10 3.0\n",
      "262 10 3.0\n",
      "263 10 7.0\n",
      "264 10 3.0\n",
      "266 10 7.0\n",
      "267 10 12.0\n",
      "268 10 6.0\n",
      "269 10 4.0\n",
      "270 10 12.0\n",
      "271 10 6.0\n",
      "272 10 12.0\n",
      "273 10 9.0\n",
      "274 10 12.0\n",
      "275 10 4.0\n",
      "276 10 8.0\n",
      "277 10 13.0\n",
      "278 10 2.0\n",
      "279 10 6.0\n",
      "Errors:  265 Accuracy: 5.36%\n",
      "Misclassified:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#myPath = \"/home/jovyan/data\"\n",
    "myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "\n",
    "data = Data(myPath, features = 'fingers_palm', frames='first_middle_last',trim=False) # Include all data points, all frames\n",
    "mod_data = Data_Mods(data,\"center\")\n",
    "#mod_data = Data_Mods(data,\"center translate scale angles\")\n",
    "#mod_data = Data_Mods(data,\"center translated scaled delta\")\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('raw','all')\n",
    "print(\"Raw, single vector per trial\")\n",
    "print(X_data.shape)\n",
    "print(X_data[0])\n",
    "print(y_data[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','all')\n",
    "print(\"Modified, single vector per trial\")\n",
    "print(X_data.shape)\n",
    "print(X_data[0])\n",
    "print(y_data[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','by_frame')\n",
    "print(\"Modified, vector for each frame of trial\")\n",
    "print(X_data.shape)\n",
    "print(X_data[0])\n",
    "print(y_data[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "mid_frame_X_train = np.array(list(zip(*X_data))[1]) # Get just the middle frames of a first_middle_last data pull\n",
    "                                                    # NOTE: only works if concatenate is by_frame\n",
    "print(\"Looking at just the middle frames for the first three trials\")\n",
    "print(mid_frame_X_train.shape)\n",
    "print(mid_frame_X_train[0:3])\n",
    "print(\"\\n\")\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','all')\n",
    "mod_data.shuffle(X_data,y_data)\n",
    "print(\"pre-split X_train size:\",mod_data.X_train.shape)\n",
    "print(\"pre-split y_train size:\",mod_data.y_train.shape)\n",
    "mod_data.split_data(0.8)\n",
    "print(\"pre-split X_train size:\",mod_data.X_train.shape)\n",
    "print(\"pre-split y_train size:\",mod_data.y_train.shape)\n",
    "\n",
    "print(\"pre-split X_test size:\",mod_data.X_test.shape)\n",
    "print(\"pre-split y_test size:\",mod_data.y_test.shape)\n",
    "\n",
    "clf = svm.SVC(gamma=0.01, decision_function_shape='ovo')\n",
    "clf_stat = clf.fit(mod_data.X_train, mod_data.y_train)  \n",
    "print(clf_stat)\n",
    "\n",
    "clf.decision_function_shape = \"ovr\"\n",
    "y_hat = clf.decision_function(mod_data.X_test)\n",
    "print(y_hat.shape)\n",
    "print(y_hat)\n",
    "print(y_hat[0])\n",
    "print(mod_data.y_test)\n",
    "\n",
    "err = 0\n",
    "errs = []\n",
    "for i in range(len(mod_data.y_test)):\n",
    "    guess = np.argmax(y_hat[i])\n",
    "    if guess != mod_data.y_test[i]:\n",
    "        print(i,guess,mod_data.y_test[i])\n",
    "        err += 1\n",
    "        errs.append(i)\n",
    "        \n",
    "print(\"Errors: {0:4d} Accuracy: {1:4.2f}%\".format(err,(1-err/len(mod_data.y_test))*100))\n",
    "print(\"Misclassified: \",errs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing  center  modification\n",
      "Performing  delta  modification\n",
      "[[ 3.  7.  5. 11.  0.  0.  0.  0.  0.  2.  0.  0.  0.  0.]\n",
      " [ 3. 18.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  3.  1.  7.  7.  1.  0.  0.  0.  2.  0.  0.  0.  0.]\n",
      " [ 0.  0.  2.  7.  0. 15.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  4.  0.  0.  0. 15.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  2.  3.  0.  7.  0. 14.  0.  2.  0.  0.  0.  0.]\n",
      " [ 0.  0. 13.  0.  0.  0.  0.  0.  9.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  3.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0. 17.  1.  2.  2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0. 12.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0. 16.  0.]\n",
      " [ 0.  1.  6.  1.  0.  0.  1.  0.  0.  5.  0.  1.  0.  1.]]\n",
      "280\n",
      "Errors:  114 Accuracy: 59.29%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "\n",
    "data = Data(myPath, features = 'all', frames='first_middle_last',trim=True) # Include all data points, all frames\n",
    "#mod_data = Data_Mods(data,\"center\")\n",
    "mod_data = Data_Mods(data,\"center delta\")\n",
    "#mod_data = Data_Mods(data,\"center translated scaled delta\")\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','all')\n",
    "mod_data.shuffle(X_data,y_data)\n",
    "mod_data.split_data(0.8)\n",
    "'''\n",
    "clf = svm.SVC(gamma=0.01, decision_function_shape='ovo')\n",
    "clf_stat = clf.fit(mod_data.X_train, mod_data.y_train)  \n",
    "\n",
    "clf.decision_function_shape = \"ovr\"\n",
    "y_hat = clf.decision_function(mod_data.X_test)\n",
    "'''\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=59)\n",
    "knn_stat = knn.fit(mod_data.X_train, mod_data.y_train)\n",
    "guesses = knn.predict(mod_data.X_test)\n",
    "err = 0\n",
    "errs = []\n",
    "        \n",
    "# Confusion matrix where rows are true labels, columns are predictions\n",
    "confusion_matrix = np.zeros(shape=(14,14))\n",
    "for i in range(len(mod_data.y_test)):\n",
    "    #print(y_hat[i])\n",
    "    guess = guesses[i]\n",
    "    confusion_matrix[int(mod_data.y_test[i]) - 1][int(guess) - 1] += 1\n",
    "    if int(guess) != int(mod_data.y_test[i]):\n",
    "        err += 1\n",
    "        errs.append(i)      \n",
    "print(confusion_matrix)        \n",
    "print (len(mod_data.y_test))\n",
    "print(\"Errors: {0:4d} Accuracy: {1:4.2f}%\".format(err,(1-err/len(mod_data.y_test))*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing  scale  modification\n",
      "[[10.  2.  0.  5.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1. 18.  0.  4.  2.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 24.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.]\n",
      " [ 4.  0.  0.  8.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  3. 16.  0.  0.  2.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0. 18.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0. 13.  0.  0.  0.  0.  0.  5.  1.]\n",
      " [ 0.  0.  0.  0.  1.  1.  0. 16.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0. 22.  0.  0.  0.  0.  2.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0. 15.  1.  1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0. 13.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 16.  0.  3.]\n",
      " [ 0.  0.  0.  0.  0.  0.  3.  0.  1.  0.  1.  3.  9.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1. 13.]]\n",
      "Errors:   69 Accuracy: 75.36%\n"
     ]
    }
   ],
   "source": [
    "myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "\n",
    "data = Data(myPath, features = 'all', frames='first_last',trim=True) # Include all data points, all frames\n",
    "#mod_data = Data_Mods(data,\"center\")\n",
    "mod_data = Data_Mods(data,\"angle\")\n",
    "#mod_data = Data_Mods(data,\"center translated scaled delta\")\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','all')\n",
    "mod_data.shuffle(X_data,y_data)\n",
    "mod_data.split_data(0.8)\n",
    "\n",
    "classifiers = []\n",
    "num_classifiers = 1\n",
    "ratio = 1\n",
    "for i in range(num_classifiers):\n",
    "    X_train, y_train = bootstrap(mod_data.X_train, mod_data.y_train, 1)\n",
    "    classifier = svm.LinearSVC()\n",
    "    classifier.fit(X_train, y_train)  \n",
    "    classifiers.append(classifier)\n",
    "\n",
    "y_hat_matrix = np.zeros(shape=(num_classifiers,len(mod_data.y_test)))\n",
    "for i in range(num_classifiers):\n",
    "    test_y_output = classifiers[i].decision_function(mod_data.X_test)\n",
    "    for j in range(len(test_y_output)):\n",
    "        y_hat = np.argmax(test_y_output[j])\n",
    "        y_hat_matrix[i][j] = y_hat\n",
    "\n",
    "\n",
    "err = 0\n",
    "errs = []\n",
    "\n",
    "# Confusion matrix where rows are true labels, columns are predictions\n",
    "confusion_matrix = np.zeros(shape=(14,14))\n",
    "for i in range(len(mod_data.y_test)):\n",
    "    #print(y_hat[i])\n",
    "    guess = voting(y_hat_matrix[:,i]) + 1\n",
    "    confusion_matrix[int(mod_data.y_test[i]) - 1][int(guess) - 1] += 1\n",
    "    if guess != mod_data.y_test[i]:\n",
    "        err += 1\n",
    "        errs.append(i)\n",
    "    \n",
    "print(confusion_matrix)        \n",
    "print(\"Errors: {0:4d} Accuracy: {1:4.2f}%\".format(err,(1-err/len(mod_data.y_test))*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing  scale  modification\n",
      "Performing  angles  modification\n",
      "[[ 4.  0.  0.  0.  3.  0.  0.  0.  1. 16.  0.  0.  0.  0.]\n",
      " [ 2.  2.  0.  0.  0.  0.  0.  0.  0. 16.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. 15.  3.  0.  0.  0.  0.]\n",
      " [ 4.  0.  0.  0.  1.  0.  0.  0.  2. 21.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  4.  0.  0.  0.  0. 14.  0.  0.  0.  0.]\n",
      " [ 2.  0.  0.  0.  1.  0.  0.  0.  1. 16.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. 20.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  7.  1. 16.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. 13.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 17.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  2. 10.  8.  0.  2.  0.]\n",
      " [ 3.  0.  0.  0.  0.  0.  0.  0.  0.  7.  0.  6.  5.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  2.  0.  0.  0. 12.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  4. 14.  0.  0.  0.  0.]]\n",
      "Errors:  207 Accuracy: 26.07%\n"
     ]
    }
   ],
   "source": [
    "myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "\n",
    "data = Data(myPath, features = 'fingertips', frames='first_middle_last',trim=True) # Include all data points, all frames\n",
    "#mod_data = Data_Mods(data,\"center\")\n",
    "mod_data = Data_Mods(data,\"scale angles\")\n",
    "#mod_data = Data_Mods(data,\"center translated scaled delta\")\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','all')\n",
    "mod_data.shuffle(X_data,y_data)\n",
    "mod_data.split_data(0.8)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf_stat = clf.fit(mod_data.X_train, mod_data.y_train)  \n",
    "\n",
    "y_hat = clf.decision_function(mod_data.X_test)\n",
    "\n",
    "err = 0\n",
    "errs = []\n",
    "\n",
    "# Confusion matrix where rows are true labels, columns are predictions\n",
    "confusion_matrix = np.zeros(shape=(14,14))\n",
    "for i in range(len(mod_data.y_test)):\n",
    "    #print(y_hat[i])\n",
    "    guess = np.argmax(y_hat[i]) + 1\n",
    "    confusion_matrix[int(mod_data.y_test[i]) - 1][int(guess) - 1] += 1\n",
    "    if guess != mod_data.y_test[i]:\n",
    "        err += 1\n",
    "        errs.append(i)\n",
    "    \n",
    "print(confusion_matrix)        \n",
    "print(\"Errors: {0:4d} Accuracy: {1:4.2f}%\".format(err,(1-err/len(mod_data.y_test))*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
