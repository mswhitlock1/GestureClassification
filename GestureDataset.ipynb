{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OS = 1 # 1 = MAC; 0 = PC\n",
    "\n",
    "COLORS_ALL = [\"green\",\"blue\",\"green\",\"gold\",\"orange\",\"orangered\",\"yellow\",\"gold\",\"orange\",\"orangered\",\n",
    "              \"yellow\",\"gold\",\"orange\",\"orangered\",\"yellow\",\"gold\",\"orange\",\"orangered\",\"yellow\",\"gold\",\n",
    "              \"orange\",\"orangered\"]\n",
    "'''\n",
    "Data class to traverse files to build up a training set\n",
    "\n",
    "directory: defines where the dataset lives on your local machine\n",
    "-- Example : \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "-- NOTE    : Set OS variable to define file system\n",
    "features: string to define which features of the hand to use.\n",
    "-- OPTIONS : 'all', 'fingertips', 'fingers_palm', 'wrist_palm'\n",
    "frames: string to define which frames of the dataset to use\n",
    "-- OPTIONS : 'all', 'first_last', 'first_middle_last', 'middle_only'\n",
    "-- OPTIONS : trim = If true, trim to start/stop frames; false = entire motion\n",
    "NUM_ESSAIS, NUM_SUBJECTS, NUM_GESTURES: Do not change if using the DHG2016 database\n",
    "'''\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, directory, features='all', frames='all', trim = True,\n",
    "                 NUM_ESSAIS = 5, NUM_SUBJECTS = 20, NUM_GESTURES = 14):\n",
    "        self.directory = directory\n",
    "        self.NUM_ESSAIS = NUM_ESSAIS\n",
    "        self.NUM_SUBJECTS = NUM_SUBJECTS\n",
    "        self.NUM_GESTURES = NUM_GESTURES\n",
    "        self.features = features\n",
    "        self.frames = frames\n",
    "        self.trim = trim\n",
    "        self.trim_data = []     # List of start/stop frames per gesture trial\n",
    "        self.concat_X_train = []\n",
    "        self.concat_y_train = []\n",
    "        \n",
    "        # Build the y_train array, assuming X_train is ordered by gesture\n",
    "        self.y_train = np.zeros(NUM_ESSAIS * NUM_SUBJECTS * NUM_GESTURES)\n",
    "        for i in range(len(self.y_train)):\n",
    "            self.y_train[i] = int(i / (NUM_SUBJECTS * NUM_ESSAIS) + 1)\n",
    "        \n",
    "        # Traverse through the directory to build training data\n",
    "        \n",
    "        if self.trim == True :\n",
    "            self.set_trim()\n",
    "            \n",
    "        self.X_train = self.traverse_data()\n",
    "        \n",
    "    # Read in the trim data file. The format is:\n",
    "    #   gesture #\n",
    "    #   finger #\n",
    "    #   subject #\n",
    "    #   essai # (trial #)\n",
    "    #   frame of the the effective beginning of the gesture\n",
    "    #   frame of the the effective end of the gesture\n",
    "    def set_trim(self):\n",
    "        if OS == 1:\n",
    "            trim_filename = self.directory + \"/informations_troncage_sequences.txt\"\n",
    "        else:\n",
    "            trim_filename = self.directory + \"\\\\informations_troncage_sequences.txt\"\n",
    "        \n",
    "        trim_file = open(trim_filename, 'r')\n",
    "        \n",
    "        # The trim database has some out-of-order elements so after reading it in, re-sort to fix it.\n",
    "        for line in trim_file:\n",
    "            numbers = [int(x) for x in line.split(' ')]\n",
    "            self.trim_data.append(numbers)\n",
    "        self.trim_data = sorted(sorted(sorted(sorted(self.trim_data, key = lambda x : x[3]), key = lambda x : x[1]),key = lambda x : x[2]), key = lambda x : x[0])\n",
    "    \n",
    "    # Traverse to parse each \"skeleton_world.txt\" file in the directory\n",
    "    def traverse_data(self):\n",
    "        \n",
    "        trials = []\n",
    "        for gesture_num in range(1, self.NUM_GESTURES + 1):\n",
    "            for subject_num in range(1, self.NUM_SUBJECTS + 1):\n",
    "                for essai_num in range(1, self.NUM_ESSAIS + 1):\n",
    "                    \n",
    "                    if self.trim == True:\n",
    "                        index = (gesture_num - 1)* 2 * self.NUM_SUBJECTS * self.NUM_ESSAIS \\\n",
    "                            + (subject_num - 1) * 2 * self.NUM_ESSAIS \\\n",
    "                            + essai_num - 1\n",
    "\n",
    "                        # a quick self-check on the dataset to make sure we're aligned\n",
    "                        if (gesture_num != self.trim_data[index][0]) or (subject_num != self.trim_data[index][2]) \\\n",
    "                            or (essai_num != self.trim_data[index][3]) :\n",
    "                            print(\"Error in truncage file sync: Gesture: \",gesture_num,\" Subject: \",subject_num,\" Trial: \",essai_num,\n",
    "                             \"index: \",index,\"trim: \",self.trim_data[index])\n",
    "                                               \n",
    "                    else:\n",
    "                        index = 0\n",
    "                        \n",
    "                    if OS == 1:\n",
    "                        trials.append(self.parse_frames(self.directory + \"/gesture_\" + \n",
    "                                                        str(gesture_num) + \"/finger_1/subject_\" + str(subject_num) + \n",
    "                                                        \"/essai_\" + str(essai_num) + \"/skeleton_world.txt\",index))\n",
    "                    else:\n",
    "                        trials.append(self.parse_frames(self.directory + \"\\\\gesture_\" + \n",
    "                                                        str(gesture_num) + \"\\\\finger_1\\\\subject_\" + str(subject_num) + \n",
    "                                                        \"\\\\essai_\" + str(essai_num) + \"\\\\skeleton_world.txt\",index))\n",
    "        return trials\n",
    "    \n",
    "    # Entry point to parse a particular file--filtering based on self.frames and self.features\n",
    "    def parse_frames(self, filename,index):\n",
    "        file = open(filename, 'r')\n",
    "        lines = []\n",
    "        for line in file:\n",
    "            lines.append(line)\n",
    "            \n",
    "        # If trimming is enabled, trim to the start/stop limits defined in the truncation file\n",
    "        if self.trim == True:\n",
    "            lines = lines[self.trim_data[index][4]:self.trim_data[index][5]+1]\n",
    "        else:\n",
    "            lines = lines[0:len(lines)]                \n",
    "        \n",
    "        # Set the 'frames' dimension based on how the data should be sampled\n",
    "        if self.frames == 'all':\n",
    "            num_frames = len(lines)\n",
    "        elif self.frames == 'first_last':\n",
    "            num_frames = 2\n",
    "        elif self.frames == 'first_middle_last':\n",
    "            num_frames = 3\n",
    "        elif self.frames == 'middle_only':\n",
    "            num_frames = 1\n",
    "        \n",
    "        # Set the 'features' dimension based on how the data should be sampled\n",
    "        if self.features == 'all':\n",
    "            num_features = 22\n",
    "        elif self.features == 'fingertips':\n",
    "            num_features = 5\n",
    "        elif self.features == 'wrist_palm':\n",
    "            num_features = 3\n",
    "        elif self.features == 'fingers_palm':\n",
    "            num_features = 6\n",
    "            \n",
    "        frames = []\n",
    "        \n",
    "        # Add frames in a particular way, depending on the filtering strategy\n",
    "        if self.frames == 'all':\n",
    "            for i in range(len(lines)):\n",
    "                line = lines[i]\n",
    "                frames.append(self.parse_frame(line))\n",
    "                \n",
    "        elif self.frames == 'first_last':\n",
    "            frames.append(self.parse_frame(lines[0]))\n",
    "            frames.append(self.parse_frame(lines[len(lines) - 1]))\n",
    "            \n",
    "        elif self.frames == 'first_middle_last':\n",
    "            frames.append(self.parse_frame(lines[0]))\n",
    "            frames.append(self.parse_frame(lines[int(len(lines) / 2)]))\n",
    "            frames.append(self.parse_frame(lines[len(lines) - 1]))\n",
    "            \n",
    "        elif self.frames == 'middle_only':\n",
    "            frames.append(self.parse_frame(lines[int(len(lines) / 2)]))\n",
    "            \n",
    "        return frames\n",
    "\n",
    "    # Parse an individual frame (line in a file)\n",
    "    def parse_frame(self, line):\n",
    "        numbers = line.split(' ')\n",
    "        full_frame = np.zeros((22,3))\n",
    "        \n",
    "        for j in range(len(numbers)):\n",
    "            full_frame[int(j / 3)][j % 3] = numbers[j]\n",
    "        \n",
    "        # Add features on the hand in a particular way, depending on the filtering strategy\n",
    "        \n",
    "        frame = []\n",
    "        if self.features == 'all':\n",
    "            for i in range (0,22):\n",
    "                frame.append([full_frame[i],COLORS_ALL[i]])\n",
    "            return frame\n",
    "        \n",
    "        elif self.features == 'fingertips':\n",
    "            frame.append([full_frame[5],COLORS_ALL[5]])\n",
    "            frame.append([full_frame[9],COLORS_ALL[9]])\n",
    "            frame.append([full_frame[13],COLORS_ALL[13]])\n",
    "            frame.append([full_frame[17],COLORS_ALL[17]])\n",
    "            frame.append([full_frame[21],COLORS_ALL[21]])\n",
    "            return frame\n",
    "        \n",
    "        elif self.features == 'wrist_palm':\n",
    "            frame.append([full_frame[0],COLORS_ALL[0]])\n",
    "            frame.append([full_frame[1],COLORS_ALL[1]])\n",
    "            frame.append([full_frame[2],COLORS_ALL[2]])\n",
    "            return frame\n",
    "\n",
    "        elif self.features == 'fingers_palm':\n",
    "            frame.append([full_frame[1],COLORS_ALL[1]])\n",
    "            frame.append([full_frame[5],COLORS_ALL[5]])\n",
    "            frame.append([full_frame[9],COLORS_ALL[9]])\n",
    "            frame.append([full_frame[13],COLORS_ALL[13]])\n",
    "            frame.append([full_frame[17],COLORS_ALL[17]])\n",
    "            frame.append([full_frame[21],COLORS_ALL[21]])\n",
    "            return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# When instantiated, this class will take the data of class Data and perform the modifications defined in \n",
    "# the pass parameter mods. The mods are performed in a defined sequence. A step in the sequence may be \n",
    "# skipped by not passing in a request for that mod but the order of the mods cannot be changed (e.g translate\n",
    "# will always occur before scale.\n",
    "\n",
    "# See the individual mods for a description of their algorithm.\n",
    "# Inputs:\n",
    "#   data: a Data class structure\n",
    "#   mods: a string containing the mods to perform\n",
    "#\n",
    "class Data_Mods:\n",
    "    def __init__(self,data,mods):\n",
    "        \n",
    "        self.raw_X_train = data.X_train\n",
    "        self.raw_y_train = data.y_train\n",
    "        \n",
    "        self.mod_X_train = cp.deepcopy(data.X_train)   # A working array to hold the data as it's modified\n",
    "        self.mod_y_train = cp.deepcopy(data.y_train)\n",
    "\n",
    "        debug = False\n",
    "        \n",
    "        if debug == True:\n",
    "            printFrame(self.raw_X_train[0][0])\n",
    "            display(self.raw_X_train[0]) \n",
    "\n",
    "        if \"center\" in mods:\n",
    "            print(\"Centering\")\n",
    "            self.center()\n",
    "\n",
    "            if debug == True:\n",
    "                printFrame(self.mod_X_train[0][0])\n",
    "                display(self.mod_X_train[0]) \n",
    "\n",
    "        if \"translate\" in mods:\n",
    "            print(\"Procustes Translation\")\n",
    "            self.translate()\n",
    "            \n",
    "            if debug == True:\n",
    "                printFrame(self.mod_X_train[0][0])\n",
    "                display(self.mod_X_train[0]) \n",
    "\n",
    "        if \"scale\" in mods:\n",
    "            print(\"Procustes Scaling\")\n",
    "            self.scale()\n",
    "            \n",
    "            if debug == True:\n",
    "                printFrame(self.mod_X_train[0][0])\n",
    "                display(self.mod_X_train[0]) \n",
    "           \n",
    "    def minMax(self,val,lmin,lmax,lsum):\n",
    "        \n",
    "        if val < lmin:\n",
    "            lmin = val\n",
    "        elif val > lmax:\n",
    "            lmax = val\n",
    "\n",
    "        lsum += val\n",
    "\n",
    "        return(lmin,lmax,lsum)\n",
    "            \n",
    "    # This function collects various stats about the data frame passed in\n",
    "    def stats(self,frame):\n",
    "        x_min  = 10000\n",
    "        x_max  = -10000\n",
    "        x_mean = 0\n",
    "        \n",
    "        y_min = 10000\n",
    "        y_max = -10000\n",
    "        y_mean = 0\n",
    "        \n",
    "        z_min = 10000\n",
    "        z_max = -10000\n",
    "        z_mean = 0\n",
    "            \n",
    "        joint_cnt = 0\n",
    "        for joint in frame:\n",
    "            [x_min,x_max,x_mean] = self.minMax(joint[0][0],x_min,x_max,x_mean)\n",
    "            [y_min,y_max,y_mean] = self.minMax(joint[0][1],y_min,y_max,y_mean)\n",
    "            [z_min,z_max,z_mean] = self.minMax(joint[0][2],z_min,z_max,z_mean)\n",
    "            \n",
    "            joint_cnt += 1\n",
    "        \n",
    "        x_mean = x_mean/joint_cnt\n",
    "        y_mean = y_mean/joint_cnt\n",
    "        z_mean = z_mean/joint_cnt\n",
    "        \n",
    "        return (x_min,x_mean,x_max,y_min,y_mean,y_max,z_min,z_mean,z_max)\n",
    "        \n",
    "    # This function translates all the gestures such that the wrist (point 0)\n",
    "    # resides at 0.5, 0.5, 0.5 to remove variation between trials and subjects\n",
    "    # \n",
    "    # The input is the sequence of frames for a gesture where the array dimensions are:\n",
    "    #     [trial #][frame #][hand joint #][position array = 0, color = 1][x = 0, y = 1, z = 2]\n",
    "    def center(self):\n",
    "        \n",
    "        # find the global mins for each axis\n",
    "        gx_min = 1000\n",
    "        gy_min = 1000\n",
    "        gz_min = 1000\n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                [x_min,x_mean,x_max,y_min,y_mean,y_max,z_min,z_mean,z_max] = mod_data.stats(frame)\n",
    "                if x_min < gx_min:\n",
    "                    gx_min = x_min\n",
    "\n",
    "                if y_min < gy_min:\n",
    "                    gy_min = y_min\n",
    "                    \n",
    "                if z_min < gz_min:\n",
    "                    gz_min = z_min\n",
    "         \n",
    "        # Center all the frames up by the global min or 1.0 which ever is greater so there \n",
    "        # are no negative coordinates\n",
    "        \n",
    "        offset_x = 1.0\n",
    "        offset_y = 1.0\n",
    "        offset_z = 1.0\n",
    "        \n",
    "        if gx_min < 0:\n",
    "            offset_x += abs(gx_min)\n",
    "        if gy_min < 0:\n",
    "            offset_y += abs(gy_min)\n",
    "        if gz_min < 0:\n",
    "            offset_z += + abs(gz_min)\n",
    "            \n",
    "#        print(gx_min,gy_min,gz_min)\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            \n",
    "            # Calculate how far to move this trial to be centered on the common point\n",
    "            cx = offset_x - trial[0][0][0][0]\n",
    "            cy = offset_y - trial[0][0][0][1]\n",
    "            cz = offset_z - trial[0][0][0][2]\n",
    "            \n",
    "            # Move all the data points in each frame for this trial by that common offset\n",
    "            for frame in trial:\n",
    "                for joint in frame:\n",
    "                    joint[0][0] += cx\n",
    "                    joint[0][1] += cy\n",
    "                    joint[0][2] += cz\n",
    "             \n",
    "    # Perform a Procustes translation\n",
    "    # \n",
    "    # Modifies the mod data frames where all x, y, z coordinates are divided by the x mean, y mean, z mean respectively\n",
    "    def translate(self):\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                [x_min,x_mean,x_max,y_min,y_mean,y_max,z_min,z_mean,z_max] = mod_data.stats(frame)\n",
    "                for joint in frame:\n",
    "                    joint[0][0] = joint[0][0]/x_mean\n",
    "                    joint[0][1] = joint[0][1]/y_mean\n",
    "                    joint[0][2] = joint[0][2]/z_mean                \n",
    "\n",
    "    def scale(self):\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                lsum = 0\n",
    "                for joint in frame:\n",
    "                    lsum += joint[0][0]**2 + joint[0][1]**2 + joint[0][2]**2\n",
    "                lscale = math.sqrt(lsum/len(frame))\n",
    "             \n",
    "                for joint in frame:\n",
    "                    joint[0][0] = joint[0][0]/lscale\n",
    "                    joint[0][1] = joint[0][1]/lscale\n",
    "                    joint[0][2] = joint[0][2]/lscale                \n",
    "  \n",
    "    # This function creates vectors out of the data. \n",
    "    #   data_set - \"raw\" = use the original, unmodified data\n",
    "    #              \"modified\" = use the modified data \n",
    "    #\n",
    "    #   concat - \"by_frame\" = Each trial, each frame will be individually concatenated into a vector (frame \n",
    "    #                         vectors) and the trial will have the dimensionality of the number of frames in \n",
    "    #                         that trial. The trial is now a frames dimensional list of frame vectors \n",
    "    #            \"all\" = For each trial, all frames for a that trial are concatenated together in order of time stamp\n",
    "    def concatenate(self,data_set=\"raw\",concat=\"by_frame\"):\n",
    "        if data_set == 'modified':\n",
    "            data = self.mod_X_train\n",
    "        else:\n",
    "            data = self.raw_X_train\n",
    "            \n",
    "        gest_cnt = 0\n",
    "        concat_X_train = []\n",
    "        concat_y_train = []\n",
    "\n",
    "        for trial in data:\n",
    "            if concat == \"by_frame\":\n",
    "                tmp_frame = []\n",
    "                for frame in trial:\n",
    "                    tmp_axis = []\n",
    "                    for joint in frame:\n",
    "                        for axis in joint[0]:\n",
    "                            tmp_axis.append(axis)\n",
    "                    tmp_frame.append(tmp_axis)\n",
    "                concat_X_train.append(tmp_frame)\n",
    "                concat_y_train.append(self.raw_y_train[gest_cnt])\n",
    "                gest_cnt += 1\n",
    "            else:\n",
    "                tmp_work = []\n",
    "                for frame in trial:\n",
    "                    for joint in frame:\n",
    "                        for axis in joint[0]:\n",
    "                            tmp_work.append(axis)\n",
    "                concat_X_train.append(tmp_work)\n",
    "                concat_y_train.append(self.raw_y_train[gest_cnt])\n",
    "                gest_cnt += 1\n",
    "\n",
    "        return (np.array(concat_X_train),np.array(concat_y_train))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Randomize:\n",
    "    \n",
    "    # This function does a basic randomization. It returns pct of the data passed in \n",
    "    # randomized for the training set and the remaining 1-pct as the test set\n",
    "    #\n",
    "    # x_data  - the x dataset\n",
    "    # y_data  - the matching y dataset\n",
    "    # pct     - percent split between training and test\n",
    "    # gesture - -1 if all gestures included, >= 0 defines gesture that will have y = 1\n",
    "    #           all other gestures will be -1\n",
    "    def vector(self,x_data,y_data,pct = 0.75,gesture=-1):\n",
    "        \n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        \n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        print(x_data.shape)\n",
    "\n",
    "        return(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myPath = \"/home/jovyan/data\"\n",
    "#myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "\n",
    "data = Data(myPath, features = 'all', frames='all',trim=True) # Include all data points, all frames\n",
    "#data = Data(myPath, features = 'fingertips', frames='first_middle_last') # fingertips only, using 3 frames at beginning middle, end of the gesture\n",
    "#data = Data(myPath, features = 'wrist_palm', frames='middle_only') # wrist and palm points using only the middle frame\n",
    "\n",
    "display(data.X_train[0]) # plot (in 2D the first gesture in the training set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up an SVM Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes only: display each frame of the first trial\n",
    "def display(trial):\n",
    "            \n",
    "    f_cnt = 0\n",
    "    for frame in trial:\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        clr = []\n",
    "        \n",
    "        for feature in frame:\n",
    "            x_vals.append(feature[0][0])\n",
    "            y_vals.append(feature[0][1])\n",
    "            clr.append(feature[1])\n",
    "            \n",
    "        plt.scatter(x_vals, y_vals,c=clr)\n",
    "        plt.title(\"Frame \" + str(f_cnt))\n",
    "        plt.show()\n",
    "        f_cnt += 1\n",
    "\n",
    "# Another helper function to print out a frame\n",
    "def printFrame(frame):\n",
    "\n",
    "    print(\"   X      Y     Z    Color\")\n",
    "    for feature in frame:\n",
    "        print(\"{0:6.3f} {1:6.3f} {2:6.3f} {3}\".format(feature[0][0],feature[0][1],feature[0][2],feature[1]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "MAX_ITER = 5\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return (1 + np.dot(x1, x2))\n",
    "    \n",
    "def polynomial_kernel(x1, x2, p = 3):\n",
    "    return (1 + np.dot(x1, x2)) ** p\n",
    "    \n",
    "def gaussian_kernel(x1, x2, sigma = 0.5):\n",
    "    return np.exp(-LA.norm(x1-x2)**2 / (2 * (sigma ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPerceptron:\n",
    "    def __init__(self, kernel = linear_kernel, Niter = 1):\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.Niter = Niter\n",
    "        self.support_vector_x = None\n",
    "        self.support_vector_y = None\n",
    "        self.alpha = []\n",
    "        self.bias = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        self.alpha = np.zeros(n_samples, dtype=np.float64)\n",
    "        self.bias = np.zeros(n_samples, dtype=np.float64)\n",
    "\n",
    "        for iter in range(self.Niter):\n",
    "            for i in range(n_samples):\n",
    "                sum = 0\n",
    "                for j in range(n_samples): \n",
    "                    sum += self.alpha[j]*y[j]*(self.kernel(X[j],X[i]))\n",
    "                if sum * y[i] <= 0:\n",
    "                    self.alpha[i] += 1\n",
    "                   \n",
    "      # Support vectors\n",
    "        sv = self.alpha > 1e-5 # ignore really small alphas - probably rounding issues\n",
    "        self.alpha = self.alpha[sv]\n",
    "        self.bias = self.bias[sv]\n",
    "        self.support_vector_x = X[sv]\n",
    "        self.support_vector_y = y[sv]\n",
    "        print(np.count_nonzero(sv),\" support vectors.\")    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        y_predict = np.zeros(len(X))\n",
    "        for i in range(len(X)):\n",
    "            sum = 0\n",
    "            for j in range(self.alpha.shape[0]):\n",
    "                sum += self.alpha[j] * self.support_vector_y[j] * self.kernel(X[i], self.support_vector_x[j]+self.bias[j])\n",
    "            y_predict[i] = sum\n",
    "        return np.sign(y_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myPath = \"/home/jovyan/data\"\n",
    "#myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "\n",
    "data = Data(myPath, features = 'all', frames='first_middle_last',trim=True) # Include all data points, all frames\n",
    "mod_data = Data_Mods(data,\"centered translated scaled\")\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('raw','all')\n",
    "print(\"Raw, single vector per trial\")\n",
    "print(X_data.shape)\n",
    "print(X_data[0])\n",
    "print(y_data[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','all')\n",
    "print(\"Modified, single vector per trial\")\n",
    "print(X_data.shape)\n",
    "print(X_data[0])\n",
    "print(y_data[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','by_frame')\n",
    "print(\"Modified, vector for each frame of trial\")\n",
    "print(X_data.shape)\n",
    "print(X_data[0])\n",
    "print(y_data[0])\n",
    "print(\"\\n\")\n",
    "mid_frame_X_train = X_data[:,1,:] # Get just the middle frames of a first_middle_last data pull\n",
    "                                  # NOTE: only works if concatenate is by_frame\n",
    "print(\"Looking at just the middle frames for the first three trials\")\n",
    "print(mid_frame_X_train.shape)\n",
    "print(mid_frame_X_train[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "#scrap code...\n",
    "\n",
    "[X_train,y_train,X_test,y_test] = Randomize.vector(X_data,y_data,.8)\n",
    "#print(data.y_train.shape)\n",
    "#print(y_train.shape,\" - \",y_train[0:5])\n",
    "#print(X_train.shape,X_train.shape[0])\n",
    "#print(mid_frame_X_train.shape)\n",
    "#print(mid_frame_X_train[0:2,:])\n",
    "#print(\"*\")\n",
    "#print(X_train[0:2,1,:])\n",
    "#print(\"**\")\n",
    "#print(X_train[0])\n",
    "d = 1\n",
    "Niter = 20\n",
    "\n",
    "# print(\"\\nLinear Kernel\")\n",
    "# kp = KernelPerceptron(linear_kernel,Niter)\n",
    "# kp.fit(data.X_train[0],data.y_train[0])\n",
    "# y_hat = kp.predict(data.X_test)\n",
    "# err = 0\n",
    "# errs = []\n",
    "# for i in range(len(data.y_test)):\n",
    "#     if y_hat[i] != data.y_test[i]:\n",
    "#         err += 1\n",
    "#         errs.append(i)\n",
    "# print(\"Errors: {0:4d} Accuracy: {1:4.2f}%\".format(err,(1-err/len(data.y_test))*100))\n",
    "# print(\"Misclassified: \",errs)\n",
    "\n",
    "# print(\"\\nPolynomial Kernel\")\n",
    "# kp = KernelPerceptron(polynomial_kernel,Niter)\n",
    "# kp.fit(data.X_train,data.y_train)\n",
    "# y_hat = kp.predict(data.X_test)\n",
    "# err = 0\n",
    "# errs = []\n",
    "# for i in range(len(data.y_test)):\n",
    "#     if y_hat[i] != data.y_test[i]:\n",
    "#         err += 1\n",
    "#         errs.append(i)\n",
    "# print(\"Errors: {0:4d} Accuracy: {1:4.2f}%\".format(err,(1-err/len(data.y_test))*100))\n",
    "# print(\"Misclassified: \",errs)\n",
    "\n",
    "# print(\"\\nGaussian Kernel\")\n",
    "# kp = KernelPerceptron(gaussian_kernel,Niter)\n",
    "# kp.fit(data.X_train,data.y_train)\n",
    "# y_hat = kp.predict(data.X_test)\n",
    "# err = 0\n",
    "# errs = []\n",
    "# for i in range(len(data.y_test)):\n",
    "#     if y_hat[i] != data.y_test[i]:\n",
    "#         err += 1\n",
    "#         errs.append(i)\n",
    "# print(\"Errors: {0:4d} Accuracy: {1:4.2f}%\".format(err,(1-err/len(data.y_test))*100))\n",
    "# print(\"Misclassified: \",errs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
