{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "OS = 1 # 1 = MAC; 0 = PC\n",
    "\n",
    "COLORS_ALL = [\"green\",\"blue\",\"green\",\"gold\",\"orange\",\"orangered\",\"yellow\",\"gold\",\"orange\",\"orangered\",\n",
    "              \"yellow\",\"gold\",\"orange\",\"orangered\",\"yellow\",\"gold\",\"orange\",\"orangered\",\"yellow\",\"gold\",\n",
    "              \"orange\",\"orangered\"]\n",
    "'''\n",
    "Data class to traverse files to build up a training set\n",
    "\n",
    "directory: defines where the dataset lives on your local machine\n",
    "-- Example : \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "-- NOTE    : Set OS variable to define file system\n",
    "features: string to define which features of the hand to use.\n",
    "-- OPTIONS : 'all', 'fingertips', 'fingers_palm', 'wrist_palm'\n",
    "frames: string to define which frames of the dataset to use\n",
    "-- OPTIONS : 'all', 'first_last', 'first_middle_last', 'middle_only'\n",
    "-- OPTIONS : trim = If true, trim to start/stop frames; false = entire motion\n",
    "NUM_ESSAIS, NUM_SUBJECTS, NUM_GESTURES: Do not change if using the DHG2016 database\n",
    "'''\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, directory, features='all', frames='all', trim = True, trim_max = 4,\n",
    "                 NUM_ESSAIS = 5, NUM_SUBJECTS = 20, NUM_GESTURES = 14):\n",
    "        self.directory = directory\n",
    "        self.NUM_ESSAIS = NUM_ESSAIS\n",
    "        self.NUM_SUBJECTS = NUM_SUBJECTS\n",
    "        self.NUM_GESTURES = NUM_GESTURES\n",
    "        self.features = features\n",
    "        self.frames = frames\n",
    "        self.trim = trim\n",
    "        self.trim_data = []     # List of start/stop frames per gesture trial\n",
    "        self.trim_max = trim_max\n",
    "        self.frames_min = 1000\n",
    "        self.frames_max = 0\n",
    "        self.concat_X_train = []\n",
    "        self.concat_y_train = []\n",
    "        \n",
    "        # Build the y_train array, assuming X_train is ordered by gesture\n",
    "        self.y_train = np.zeros(NUM_ESSAIS * NUM_SUBJECTS * NUM_GESTURES)\n",
    "        for i in range(len(self.y_train)):\n",
    "            self.y_train[i] = int(i / (NUM_SUBJECTS * NUM_ESSAIS) + 1)\n",
    "        \n",
    "        # Traverse through the directory to build training data\n",
    "        \n",
    "        if self.trim == True :\n",
    "            self.set_trim()\n",
    "            \n",
    "        self.X_train = self.traverse_data()\n",
    "\n",
    "    def interpolate(self,frames):\n",
    "        \n",
    "        tstep = (len(frames)-1)/(self.trim_max - 1)\n",
    "        new_frame = [[] for i in range(self.trim_max)]\n",
    "\n",
    "        for j_index in range(0,len(frames[0])): #gives joints\n",
    "            new_d = []\n",
    "            t = 0\n",
    "            color = frames[0][j_index][1]\n",
    "            for step in range (0,self.trim_max-1):\n",
    "                [frac,index] = math.modf(t)\n",
    "                index = int(index)\n",
    "                delta_x = frames[index][j_index][0][0] + ((frames[index+1][j_index][0][0]-frames[index][j_index][0][0])*frac)\n",
    "                delta_y = frames[index][j_index][0][1] + ((frames[index+1][j_index][0][1]-frames[index][j_index][0][1])*frac)\n",
    "                delta_z = frames[index][j_index][0][2] + ((frames[index+1][j_index][0][2]-frames[index][j_index][0][2])*frac)\n",
    "\n",
    "                new_frame[step].append([[delta_x,delta_y,delta_z],color])\n",
    "                t = t + tstep\n",
    "\n",
    "            last_pos = frames[len(frames)-1][j_index][0]\n",
    "            new_frame[self.trim_max-1].append([[last_pos[0],last_pos[1],last_pos[2]],color])\n",
    "        \n",
    "        return(new_frame)\n",
    "        \n",
    "    # Read in the trim data file. The format is:\n",
    "    #   gesture #\n",
    "    #   finger #\n",
    "    #   subject #\n",
    "    #   essai # (trial #)\n",
    "    #   frame of the the effective beginning of the gesture\n",
    "    #   frame of the the effective end of the gesture\n",
    "    def set_trim(self):\n",
    "        if OS == 1:\n",
    "            trim_filename = self.directory + \"/informations_troncage_sequences.txt\"\n",
    "        else:\n",
    "            trim_filename = self.directory + \"\\\\informations_troncage_sequences.txt\"\n",
    "        \n",
    "        trim_file = open(trim_filename, 'r')\n",
    "        \n",
    "        # The trim database has some out-of-order elements so after reading it in, re-sort to fix it.\n",
    "        for line in trim_file:\n",
    "            numbers = [int(x) for x in line.split(' ')]\n",
    "            self.trim_data.append(numbers)\n",
    "        self.trim_data = sorted(sorted(sorted(sorted(self.trim_data, key = lambda x : x[3]), key = lambda x : x[1]),key = lambda x : x[2]), key = lambda x : x[0])\n",
    "    \n",
    "        # Collect statistics on the length of the gesture frames\n",
    "        f_sum = 0\n",
    "        for line in self.trim_data:\n",
    "            self.frames_min = min(self.frames_min,line[5]-line[4]+1)\n",
    "            self.frames_max = max(self.frames_max,line[5]-line[4]+1)\n",
    "            f_sum += line[5]-line[4]+1\n",
    "            \n",
    "        f_avg = f_sum/len(self.trim_data)\n",
    "        print(\"Total Gestures: %4i\\tAvg Frames/Gesture: %.3f\\tShortest Gesture: %.3f\\tLongest Gesture: %.3f\"%(len(self.trim_data),f_avg,self.frames_min,self.frames_max))\n",
    "\n",
    "    # Traverse to parse each \"skeleton_world.txt\" file in the directory\n",
    "    def traverse_data(self):\n",
    "        \n",
    "        trials = []\n",
    "        for gesture_num in range(1, self.NUM_GESTURES + 1):\n",
    "            for subject_num in range(1, self.NUM_SUBJECTS + 1):\n",
    "                for essai_num in range(1, self.NUM_ESSAIS + 1):\n",
    "                    \n",
    "                    if self.trim == True:\n",
    "                        index = (gesture_num - 1)* 2 * self.NUM_SUBJECTS * self.NUM_ESSAIS \\\n",
    "                            + (subject_num - 1) * 2 * self.NUM_ESSAIS \\\n",
    "                            + essai_num - 1\n",
    "\n",
    "                        # a quick self-check on the dataset to make sure we're aligned\n",
    "                        if (gesture_num != self.trim_data[index][0]) or (subject_num != self.trim_data[index][2]) \\\n",
    "                            or (essai_num != self.trim_data[index][3]) :\n",
    "                            print(\"Error in truncage file sync: Gesture: \",gesture_num,\" Subject: \",subject_num,\" Trial: \",essai_num,\n",
    "                             \"index: \",index,\"trim: \",self.trim_data[index])\n",
    "                                               \n",
    "                    else:\n",
    "                        index = 0\n",
    "                        \n",
    "                    if OS == 1:\n",
    "                        trials.append(self.parse_frames(self.directory + \"/gesture_\" + \n",
    "                                                        str(gesture_num) + \"/finger_1/subject_\" + str(subject_num) + \n",
    "                                                        \"/essai_\" + str(essai_num) + \"/skeleton_world.txt\",index))\n",
    "                    else:\n",
    "                        trials.append(self.parse_frames(self.directory + \"\\\\gesture_\" + \n",
    "                                                        str(gesture_num) + \"\\\\finger_1\\\\subject_\" + str(subject_num) + \n",
    "                                                        \"\\\\essai_\" + str(essai_num) + \"\\\\skeleton_world.txt\",index))\n",
    "        return trials\n",
    "    \n",
    "    # Entry point to parse a particular file--filtering based on self.frames and self.features\n",
    "    def parse_frames(self, filename,index):\n",
    "        file = open(filename, 'r')\n",
    "        lines = []\n",
    "        for line in file:\n",
    "            lines.append(line)\n",
    "            \n",
    "        # If trimming is enabled, trim to the start/stop limits defined in the truncation file\n",
    "        if self.trim == True:\n",
    "            lines = lines[self.trim_data[index][4]:self.trim_data[index][5]+1]\n",
    "        else:\n",
    "            lines = lines[0:len(lines)]                \n",
    "        \n",
    "        # Set the 'frames' dimension based on how the data should be sampled\n",
    "        if self.frames == 'all':\n",
    "            num_frames = len(lines)\n",
    "        elif self.frames == 'first_last':\n",
    "            num_frames = 2\n",
    "        elif self.frames == 'first_middle_last':\n",
    "            num_frames = 3\n",
    "        elif self.frames == 'middle_only':\n",
    "            num_frames = 1\n",
    "        \n",
    "        # Set the 'features' dimension based on how the data should be sampled\n",
    "        if self.features == 'all':\n",
    "            num_features = 22\n",
    "        elif self.features == 'fingertips':\n",
    "            num_features = 5\n",
    "        elif self.features == 'wrist_palm':\n",
    "            num_features = 3\n",
    "        elif self.features == 'fingers_palm':\n",
    "            num_features = 6\n",
    "            \n",
    "        frames = []\n",
    "        \n",
    "        # Add frames in a particular way, depending on the filtering strategy\n",
    "        if self.frames == 'all':\n",
    "            for i in range(len(lines)):\n",
    "                line = lines[i]\n",
    "                frames.append(self.parse_frame(line))\n",
    "\n",
    "            if self.trim == True:\n",
    "                frames = self.interpolate(frames)\n",
    "                \n",
    "        elif self.frames == 'first_last':\n",
    "            frames.append(self.parse_frame(lines[0]))\n",
    "            frames.append(self.parse_frame(lines[len(lines) - 1]))\n",
    "            \n",
    "        elif self.frames == 'first_middle_last':\n",
    "            frames.append(self.parse_frame(lines[0]))\n",
    "            frames.append(self.parse_frame(lines[int(len(lines) / 2)]))\n",
    "            frames.append(self.parse_frame(lines[len(lines) - 1]))\n",
    "            \n",
    "        elif self.frames == 'middle_only':\n",
    "            frames.append(self.parse_frame(lines[int(len(lines) / 2)]))\n",
    "            \n",
    "        return frames\n",
    "\n",
    "    # Parse an individual frame (line in a file)\n",
    "    def parse_frame(self, line):\n",
    "        numbers = line.split(' ')\n",
    "        full_frame = np.zeros((22,3))\n",
    "        \n",
    "        for j in range(len(numbers)):\n",
    "            full_frame[int(j / 3)][j % 3] = numbers[j]\n",
    "        \n",
    "        # Add features on the hand in a particular way, depending on the filtering strategy\n",
    "        \n",
    "        frame = []\n",
    "        if self.features == 'all':\n",
    "            for i in range (0,22):\n",
    "                frame.append([full_frame[i],COLORS_ALL[i]])\n",
    "            return frame\n",
    "        \n",
    "        elif self.features == 'fingertips':\n",
    "            frame.append([full_frame[5],COLORS_ALL[5]])\n",
    "            frame.append([full_frame[9],COLORS_ALL[9]])\n",
    "            frame.append([full_frame[13],COLORS_ALL[13]])\n",
    "            frame.append([full_frame[17],COLORS_ALL[17]])\n",
    "            frame.append([full_frame[21],COLORS_ALL[21]])\n",
    "            return frame\n",
    "        \n",
    "        elif self.features == 'wrist_palm':\n",
    "            frame.append([full_frame[0],COLORS_ALL[0]])\n",
    "            frame.append([full_frame[1],COLORS_ALL[1]])\n",
    "            frame.append([full_frame[2],COLORS_ALL[2]])\n",
    "            return frame\n",
    "\n",
    "        elif self.features == 'fingers_palm':\n",
    "            frame.append([full_frame[1],COLORS_ALL[1]])\n",
    "            frame.append([full_frame[5],COLORS_ALL[5]])\n",
    "            frame.append([full_frame[9],COLORS_ALL[9]])\n",
    "            frame.append([full_frame[13],COLORS_ALL[13]])\n",
    "            frame.append([full_frame[17],COLORS_ALL[17]])\n",
    "            frame.append([full_frame[21],COLORS_ALL[21]])\n",
    "            return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random as rnd\n",
    "\n",
    "# When instantiated, this class will take the data of class Data and perform the modifications defined in \n",
    "# the pass parameter mods. The mods are performed in a defined sequence. A step in the sequence may be \n",
    "# skipped by not passing in a request for that mod but the order of the mods cannot be changed (e.g translate\n",
    "# will always occur before scale.\n",
    "\n",
    "# See the individual mods for a description of their algorithm.\n",
    "# Inputs:\n",
    "#   data: a Data class structure\n",
    "#   mods: a string containing the mods to perform in the order that the mods should be performed\n",
    "#\n",
    "class Data_Mods:\n",
    "    def __init__(self,data,mods):\n",
    "        \n",
    "        self.raw_X_train = data.X_train\n",
    "        self.raw_y_train = data.y_train\n",
    "        \n",
    "        self.mod_X_train = cp.deepcopy(data.X_train)   # A working array to hold the data as it's modified\n",
    "        self.mod_y_train = cp.deepcopy(data.y_train)\n",
    "\n",
    "        self.X_train = cp.deepcopy(data.X_train)\n",
    "        self.y_train = cp.deepcopy(data.y_train)\n",
    "        \n",
    "        self.X_test = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        # Take apart the mods string here one string at a time and call the associated function\n",
    "        switcher = {\n",
    "                    \"center\":    self.center,\n",
    "                    \"translate\": self.translate,\n",
    "                    \"scale\":     self.scale,\n",
    "                    \"angles\":    self.angles,\n",
    "                    \"angles2\":   self.angles2,\n",
    "                    \"delta\":     self.delta\n",
    "                    }\n",
    "\n",
    "        debug = False\n",
    "\n",
    "        if debug == True:\n",
    "            printFrame(self.raw_X_train[0][0])\n",
    "            display(self.raw_X_train[0]) \n",
    "\n",
    "        # A python switch statement...\n",
    "        for key in mods.split(\" \"):\n",
    "            print(\"Performing \",key,\" modification\")\n",
    "            func = switcher.get(key, \"nothing\")\n",
    "            if func == \"nothing\":\n",
    "                print(\"key: \",key,\" is invalid\")\n",
    "            else:\n",
    "                func()\n",
    "                if debug == True:\n",
    "                    printFrame(self.mod_X_train[0][0])\n",
    "                    display(self.mod_X_train[0]) \n",
    "\n",
    "    def minMax(self,val,lmin,lmax,lsum):\n",
    "        \n",
    "        if val < lmin:\n",
    "            lmin = val\n",
    "        elif val > lmax:\n",
    "            lmax = val\n",
    "\n",
    "        lsum += val\n",
    "\n",
    "        return(lmin,lmax,lsum)\n",
    "            \n",
    "    # This function collects various stats about the data frame passed in\n",
    "    def stats(self,frame):\n",
    "        x_min  = 10000\n",
    "        x_max  = -10000\n",
    "        x_mean = 0\n",
    "        \n",
    "        y_min = 10000\n",
    "        y_max = -10000\n",
    "        y_mean = 0\n",
    "        \n",
    "        z_min = 10000\n",
    "        z_max = -10000\n",
    "        z_mean = 0\n",
    "            \n",
    "        joint_cnt = 0\n",
    "        for joint in frame:\n",
    "            [x_min,x_max,x_mean] = self.minMax(joint[0][0],x_min,x_max,x_mean)\n",
    "            [y_min,y_max,y_mean] = self.minMax(joint[0][1],y_min,y_max,y_mean)\n",
    "            [z_min,z_max,z_mean] = self.minMax(joint[0][2],z_min,z_max,z_mean)\n",
    "            \n",
    "            joint_cnt += 1\n",
    "        \n",
    "        x_mean = x_mean/joint_cnt\n",
    "        y_mean = y_mean/joint_cnt\n",
    "        z_mean = z_mean/joint_cnt\n",
    "        \n",
    "        return (x_min,x_mean,x_max,y_min,y_mean,y_max,z_min,z_mean,z_max)\n",
    "        \n",
    "    # This function translates all the gestures such that the wrist (point 0)\n",
    "    # resides at 0.5, 0.5, 0.5 to remove variation between trials and subjects\n",
    "    # \n",
    "    # The input is the sequence of frames for a gesture where the array dimensions are:\n",
    "    #     [trial #][frame #][hand joint #][position array = 0, color = 1][x = 0, y = 1, z = 2]\n",
    "    def center(self):\n",
    "        \n",
    "        # find the global mins for each axis\n",
    "        gx_min = 1000\n",
    "        gy_min = 1000\n",
    "        gz_min = 1000\n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                [x_min,x_mean,x_max,y_min,y_mean,y_max,z_min,z_mean,z_max] = self.stats(frame)\n",
    "                if x_min < gx_min:\n",
    "                    gx_min = x_min\n",
    "\n",
    "                if y_min < gy_min:\n",
    "                    gy_min = y_min\n",
    "                    \n",
    "                if z_min < gz_min:\n",
    "                    gz_min = z_min\n",
    "         \n",
    "        # Center all the frames up by the global min or 1.0 which ever is greater so there \n",
    "        # are no negative coordinates\n",
    "        \n",
    "        offset_x = 1.0\n",
    "        offset_y = 1.0\n",
    "        offset_z = 1.0\n",
    "        \n",
    "        if gx_min < 0:\n",
    "            offset_x += abs(gx_min)\n",
    "        if gy_min < 0:\n",
    "            offset_y += abs(gy_min)\n",
    "        if gz_min < 0:\n",
    "            offset_z += + abs(gz_min)\n",
    "            \n",
    "#        print(gx_min,gy_min,gz_min)\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            \n",
    "            # Calculate how far to move this trial to be centered on the common point\n",
    "            cx = offset_x - trial[0][0][0][0]\n",
    "            cy = offset_y - trial[0][0][0][1]\n",
    "            cz = offset_z - trial[0][0][0][2]\n",
    "            \n",
    "            # Move all the data points in each frame for this trial by that common offset\n",
    "            for frame in trial:\n",
    "                for joint in frame:\n",
    "                    joint[0][0] += cx\n",
    "                    joint[0][1] += cy\n",
    "                    joint[0][2] += cz\n",
    "             \n",
    "    # Perform a Procustes translation\n",
    "    # \n",
    "    # Modifies the mod data frames where all x, y, z coordinates are divided by the x mean, y mean, z mean respectively\n",
    "    def translate(self):\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                [x_min,x_mean,x_max,y_min,y_mean,y_max,z_min,z_mean,z_max] = self.stats(frame)\n",
    "                for joint in frame:\n",
    "                    joint[0][0] = joint[0][0]/x_mean\n",
    "                    joint[0][1] = joint[0][1]/y_mean\n",
    "                    joint[0][2] = joint[0][2]/z_mean                \n",
    "\n",
    "    def scale(self):\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                lsum = 0\n",
    "                for joint in frame:\n",
    "                    lsum += joint[0][0]**2 + joint[0][1]**2 + joint[0][2]**2\n",
    "                lscale = math.sqrt(lsum/len(frame))\n",
    "             \n",
    "                for joint in frame:\n",
    "                    joint[0][0] = joint[0][0]/lscale\n",
    "                    joint[0][1] = joint[0][1]/lscale\n",
    "                    joint[0][2] = joint[0][2]/lscale                \n",
    "  \n",
    "    # This function coverts from X, Y, Z coordinates to X-Y Angle, X-Z Angle, Vector Length.\n",
    "    # The angles returned are in radians.\n",
    "    #\n",
    "    # Output:\n",
    "    #    Joint[0][0] = X-Y angle\n",
    "    #    Joint[0][1] = X-Z angle\n",
    "    #    Joint[0][2] = Vector length\n",
    "    \n",
    "    def angles(self):\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                for joint in frame:\n",
    "                    x = joint[0][0]\n",
    "                    y = joint[0][1]\n",
    "                    z = joint[0][2]\n",
    "                    joint[0][0] = math.atan(y/x)\n",
    "                    joint[0][1] = math.atan(z/x)\n",
    "                    joint[0][2] = math.sqrt(x**2 + y**2 + z**2)\n",
    "      \n",
    "    # This function coverts from X, Y, Z coordinates to X-Y Angle, X-Z Angle.\n",
    "    # The angles returned are in radians.\n",
    "    #\n",
    "    # Output:\n",
    "    #    Joint[0][0] = X-Y angle\n",
    "    #    Joint[0][1] = X-Z angle\n",
    "    \n",
    "    def angles2(self):\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in trial:\n",
    "                for joint in frame:\n",
    "                    x = joint[0][0]\n",
    "                    y = joint[0][1]\n",
    "                    z = joint[0][2]\n",
    "                    joint[0][0] = math.atan(y/x)\n",
    "                    joint[0][1] = math.atan(z/x)\n",
    "\n",
    "                    # Get rid of the z axis\n",
    "                    joint[0] = np.delete(joint[0],2)\n",
    "\n",
    "    # This function converts a trial from a series of frames containing absolute X, Y, Z \n",
    "    # locations to a delta between each frame. There are Frame - 1 deltas here so the last element\n",
    "    # of the array holding the modified data gets truncated by one.\n",
    "    #\n",
    "    # Output:\n",
    "    #    Joint[0][0] = X(t-1) - X(t)\n",
    "    #    Joint[0][1] = Y(t-1) - Y(t)\n",
    "    #    Joint[0][2] = Z(t-1) - Z(t)\n",
    "\n",
    "    def delta(self):\n",
    "        \n",
    "        for trial in self.mod_X_train:\n",
    "            for frame in range(len(trial)-1):\n",
    "                for joint in range(len(trial[frame])):\n",
    "                    trial[frame][joint][0][0] = trial[frame][joint][0][0] - trial[frame+1][joint][0][0]\n",
    "                    trial[frame][joint][0][1] = trial[frame][joint][0][1] - trial[frame+1][joint][0][1]\n",
    "                    trial[frame][joint][0][2] = trial[frame][joint][0][2] - trial[frame+1][joint][0][2]\n",
    "\n",
    "            trial.pop(len(trial)-1)\n",
    "\n",
    "    # This function creates vectors out of the data. \n",
    "    #   data_set - \"raw\" = use the original, unmodified data\n",
    "    #              \"modified\" = use the modified data \n",
    "    #\n",
    "    #   concat - \"by_frame\" = Each trial, each frame will be individually concatenated into a vector (frame \n",
    "    #                         vectors) and the trial will have the dimensionality of the number of frames in \n",
    "    #                         that trial. The trial is now a frames dimensional list of frame vectors \n",
    "    #            \"all\" = For each trial, all frames for a that trial are concatenated together in order of time stamp\n",
    "    def concatenate(self,data_set=\"raw\",concat=\"by_frame\"):\n",
    "        if data_set == 'modified':\n",
    "            data = self.mod_X_train\n",
    "        else:\n",
    "            data = self.raw_X_train\n",
    "            \n",
    "        gest_cnt = 0\n",
    "        concat_X_train = []\n",
    "        concat_y_train = []\n",
    "\n",
    "        for trial in data:\n",
    "            if concat == \"by_frame\":\n",
    "                tmp_frame = []\n",
    "                for frame in trial:\n",
    "                    tmp_axis = []\n",
    "                    for joint in frame:\n",
    "                        for axis in joint[0]:\n",
    "                            tmp_axis.append(axis)\n",
    "                    tmp_frame.append(tmp_axis)\n",
    "                concat_X_train.append(np.array(tmp_frame))\n",
    "                concat_y_train.append(self.raw_y_train[gest_cnt])\n",
    "                gest_cnt += 1\n",
    "            else: #\"all\"\n",
    "                tmp_work = []\n",
    "                for frame in trial:\n",
    "                    for joint in frame:\n",
    "                        for axis in joint[0]:\n",
    "                            tmp_work.append(axis)\n",
    "                concat_X_train.append(np.array(tmp_work))\n",
    "                concat_y_train.append(self.raw_y_train[gest_cnt])\n",
    "                gest_cnt += 1\n",
    "\n",
    "        return (np.array(concat_X_train),np.array(concat_y_train))\n",
    "\n",
    "    # This function does a basic randomization. It takes the dataset passed in\n",
    "    # and sets X_train, y_train to a randomized version of it\n",
    "    def shuffle(self,data_x,data_y):\n",
    "        random_indices = rnd.sample(range(len(data_x)), len(data_x))\n",
    "        new_i = 0\n",
    "        for i in random_indices:\n",
    "            self.X_train[new_i] = data_x[i]\n",
    "            self.y_train[new_i] = data_y[i]\n",
    "            new_i += 1\n",
    "            \n",
    "        self.X_train = np.array(self.X_train)\n",
    "        self.y_train = np.array(self.y_train)\n",
    "        \n",
    "    # This function sets aside pct of the data passed in for the training set and the \n",
    "    # remaining 1-pct as the test set\n",
    "    #\n",
    "    # pct     - percent split between training and test\n",
    "    # gesture - -1 if all gestures included, >= 0 defines gesture that will have y = 1\n",
    "    #           all other gestures will be -1\n",
    "    #\n",
    "    # Note: This function needs to be called after shuffle\n",
    "    def split_data(self,ratio):\n",
    "        X_data = cp.deepcopy(self.X_train)\n",
    "        y_data = cp.deepcopy(self.y_train)\n",
    "\n",
    "        train_length = int(ratio * self.X_train.shape[0])\n",
    "        self.X_test  = np.array(X_data[train_length:])\n",
    "        self.X_train = np.array(X_data[:train_length])\n",
    "        \n",
    "        self.y_test  = np.array(y_data[train_length:])\n",
    "        self.y_train = np.array(y_data[:train_length])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myPath = \"/home/jovyan/data\"\n",
    "#myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "\n",
    "data = Data(myPath, features = 'all', frames='all',trim=True) # Include all data points, all frames\n",
    "#data = Data(myPath, features = 'fingertips', frames='first_middle_last') # fingertips only, using 3 frames at beginning middle, end of the gesture\n",
    "#data = Data(myPath, features = 'wrist_palm', frames='middle_only') # wrist and palm points using only the middle frame\n",
    "\n",
    "#display(data.X_train[0]) # plot (in 2D the first gesture in the training set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up an SVM Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes only: display each frame of the trial passed in\n",
    "def display(trial):\n",
    "            \n",
    "    f_cnt = 0\n",
    "    for frame in trial:\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        clr = []\n",
    "        \n",
    "        for feature in frame:\n",
    "            x_vals.append(feature[0][0])\n",
    "            y_vals.append(feature[0][1])\n",
    "            clr.append(feature[1])\n",
    "            \n",
    "        plt.scatter(x_vals, y_vals,c=clr)\n",
    "        plt.title(\"Frame \" + str(f_cnt))\n",
    "        plt.show()\n",
    "        f_cnt += 1\n",
    "\n",
    "# Another helper function to print out a frame\n",
    "def printFrame(frame):\n",
    "\n",
    "    print(\"   X      Y     Z    Color\")\n",
    "    for feature in frame:\n",
    "        print(\"{0:6.3f} {1:6.3f} {2:6.3f} {3}\".format(feature[0][0],feature[0][1],feature[0][2],feature[1]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(X_train, y_train, ratio):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n (int): total size of the training data\n",
    "        X_train (ndarray): [n_samples x n_features] ndarray of training data   \n",
    "        y_train (ndarray): [n_samples] ndarray of data \n",
    "    \"\"\"\n",
    "    selected_indices = np.random.randint(y_train.shape[0], size=int(ratio * y_train.shape[0]))\n",
    "    return [X_train[i] for i in selected_indices], [y_train[i] for i in selected_indices]\n",
    "def voting(y_hats):\n",
    "    counts = dict()\n",
    "    for i in y_hats:\n",
    "        counts[int(i)] = counts.get(int(i), 0) + 1\n",
    "    class_num, count = max((class_num, count) for class_num, count in counts.items())\n",
    "    return class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "myPath = \"/home/jovyan/data\"\n",
    "#myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "\n",
    "data = Data(myPath, features = 'all', frames='all',trim=True, trim_max=10) # Include all data points, all frames\n",
    "mod_data = Data_Mods(data,\"angles\")\n",
    "#mod_data = Data_Mods(data,\"center translate scale angles\")\n",
    "#mod_data = Data_Mods(data,\"center translated scaled delta\")\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# [X_data,y_data] = mod_data.concatenate('raw','all')\n",
    "# print(\"Raw, single vector per trial\")\n",
    "# print(X_data.shape)\n",
    "# print(X_data[0])\n",
    "# print(y_data[0])\n",
    "# print(\"\\n\")\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','all')\n",
    "# print(\"Modified, single vector per trial\")\n",
    "# print(X_data.shape)\n",
    "# print(X_data[0])\n",
    "# print(y_data[0])\n",
    "# print(\"\\n\")\n",
    "\n",
    "# [X_data,y_data] = mod_data.concatenate('modified','by_frame')\n",
    "# print(\"Modified, vector for each frame of trial\")\n",
    "# print(X_data.shape)\n",
    "# print(X_data[0])\n",
    "# print(y_data[0])\n",
    "# print(\"\\n\")\n",
    "\n",
    "#mid_frame_X_train = np.array(list(zip(*X_data))[1]) # Get just the middle frames of a first_middle_last data pull\n",
    "#                                                     # NOTE: only works if concatenate is by_frame\n",
    "# print(\"Looking at just the middle frames for the first three trials\")\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','all')\n",
    "mod_data.shuffle(X_data,y_data)\n",
    "mod_data.split_data(0.8)\n",
    "\n",
    "clf = svm.LinearSVC()\n",
    "clf_stat = clf.fit(mod_data.X_train, mod_data.y_train)  \n",
    "\n",
    "y_hat = clf.decision_function(mod_data.X_test)\n",
    "\n",
    "err = 0\n",
    "errs = []\n",
    "\n",
    "# Confusion matrix where rows are true labels, columns are predictions\n",
    "confusion_matrix = np.zeros(shape=(14,14))\n",
    "for i in range(len(mod_data.y_test)):\n",
    "    #print(y_hat[i])\n",
    "    guess = np.argmax(y_hat[i]) + 1\n",
    "    confusion_matrix[int(mod_data.y_test[i]) - 1][int(guess) - 1] += 1\n",
    "    if guess != mod_data.y_test[i]:\n",
    "        err += 1\n",
    "        errs.append(i)\n",
    "    \n",
    "plot_title = \"SVM, Accuracy: {1:4.2f}%\".format(err,(1-err/len(mod_data.y_test))*100)\n",
    "plot_confusion_matrix(confusion_matrix, range(1,15), normalize=True, title=plot_title)\n",
    "print(\"Errors: {0:4d} Accuracy: {1:4.2f}%\".format(err,(1-err/len(mod_data.y_test))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "#myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "myPath = \"/home/jovyan/data\"\n",
    "\n",
    "data = Data(myPath, features = 'all', frames='first_middle_last',trim=True) # Include all data points, all frames\n",
    "#mod_data = Data_Mods(data,\"center\")\n",
    "mod_data = Data_Mods(data,\"center delta\")\n",
    "#mod_data = Data_Mods(data,\"center translated scaled delta\")\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','all')\n",
    "mod_data.shuffle(X_data,y_data)\n",
    "mod_data.split_data(0.8)\n",
    "'''\n",
    "clf = svm.SVC(gamma=0.01, decision_function_shape='ovo')\n",
    "clf_stat = clf.fit(mod_data.X_train, mod_data.y_train)  \n",
    "\n",
    "clf.decision_function_shape = \"ovr\"\n",
    "y_hat = clf.decision_function(mod_data.X_test)\n",
    "'''\n",
    "num_neighbors = 50\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=num_neighbors)\n",
    "knn_stat = knn.fit(mod_data.X_train, mod_data.y_train)\n",
    "guesses = knn.predict(mod_data.X_test)\n",
    "err = 0\n",
    "errs = []\n",
    "# Confusion matrix where rows are true labels, columns are predictions\n",
    "confusion_matrix = np.zeros(shape=(14,14))\n",
    "for i in range(len(mod_data.y_test)):\n",
    "    #print(y_hat[i])\n",
    "    guess = guesses[i]\n",
    "    confusion_matrix[int(mod_data.y_test[i]) - 1][int(guess) - 1] += 1\n",
    "    if int(guess) != int(mod_data.y_test[i]):\n",
    "        err += 1\n",
    "        errs.append(i)\n",
    "        \n",
    "plot_title = \"KNN, \" + str(num_neighbors) + \" neighbors, Accuracy: {1:4.2f}%\".format(err,(1-err/len(mod_data.y_test))*100)\n",
    "plot_confusion_matrix(confusion_matrix, range(1,15), normalize=True, title=plot_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "myPath = \"/home/jovyan/data\"\n",
    "\n",
    "data = Data(myPath, features = 'all', frames='first_last',trim=True) # Include all data points, all frames\n",
    "#mod_data = Data_Mods(data,\"center\")\n",
    "mod_data = Data_Mods(data,\"angles\")\n",
    "#mod_data = Data_Mods(data,\"center translated scaled delta\")\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','all')\n",
    "mod_data.shuffle(X_data,y_data)\n",
    "mod_data.split_data(0.8)\n",
    "\n",
    "classifiers = []\n",
    "num_classifiers = 1\n",
    "ratio = 1\n",
    "for i in range(num_classifiers):\n",
    "    X_train, y_train = bootstrap(mod_data.X_train, mod_data.y_train, 1)\n",
    "    classifier = svm.LinearSVC()\n",
    "    classifier.fit(X_train, y_train)  \n",
    "    classifiers.append(classifier)\n",
    "\n",
    "y_hat_matrix = np.zeros(shape=(num_classifiers,len(mod_data.y_test)))\n",
    "for i in range(num_classifiers):\n",
    "    test_y_output = classifiers[i].decision_function(mod_data.X_test)\n",
    "    for j in range(len(test_y_output)):\n",
    "        y_hat = np.argmax(test_y_output[j])\n",
    "        y_hat_matrix[i][j] = y_hat\n",
    "\n",
    "\n",
    "err = 0\n",
    "errs = []\n",
    "\n",
    "# Confusion matrix where rows are true labels, columns are predictions\n",
    "confusion_matrix = np.zeros(shape=(14,14))\n",
    "for i in range(len(mod_data.y_test)):\n",
    "    #print(y_hat[i])\n",
    "    guess = voting(y_hat_matrix[:,i]) + 1\n",
    "    confusion_matrix[int(mod_data.y_test[i]) - 1][int(guess) - 1] += 1\n",
    "    if guess != mod_data.y_test[i]:\n",
    "        err += 1\n",
    "        errs.append(i)\n",
    "    \n",
    "plot_title = \"Linear SVM, Accuracy: {1:4.2f}%\".format(err,(1-err/len(mod_data.y_test))*100)\n",
    "plot_confusion_matrix(confusion_matrix, range(1,15), normalize=True, title=plot_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#myPath = \"C:\\\\Users\\\\mswhi\\\\GestureDataset\\\\DHG2016\"\n",
    "myPath = \"/home/jovyan/data\"\n",
    "\n",
    "data = Data(myPath, features = 'fingertips', frames='first_middle_last',trim=True) # Include all data points, all frames\n",
    "#mod_data = Data_Mods(data,\"center\")\n",
    "mod_data = Data_Mods(data,\"scale angles\")\n",
    "#mod_data = Data_Mods(data,\"center translated scaled delta\")\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "[X_data,y_data] = mod_data.concatenate('modified','all')\n",
    "mod_data.shuffle(X_data,y_data)\n",
    "mod_data.split_data(0.8)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf_stat = clf.fit(mod_data.X_train, mod_data.y_train)  \n",
    "\n",
    "y_hat = clf.decision_function(mod_data.X_test)\n",
    "\n",
    "err = 0\n",
    "errs = []\n",
    "\n",
    "# Confusion matrix where rows are true labels, columns are predictions\n",
    "confusion_matrix = np.zeros(shape=(14,14))\n",
    "for i in range(len(mod_data.y_test)):\n",
    "    #print(y_hat[i])\n",
    "    guess = np.argmax(y_hat[i]) + 1\n",
    "    confusion_matrix[int(mod_data.y_test[i]) - 1][int(guess) - 1] += 1\n",
    "    if guess != mod_data.y_test[i]:\n",
    "        err += 1\n",
    "        errs.append(i)\n",
    "    \n",
    "plot_title = \"SVM, Accuracy: {1:4.2f}%\".format(err,(1-err/len(mod_data.y_test))*100)\n",
    "plot_confusion_matrix(confusion_matrix, range(1,15), normalize=True, title=plot_title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
